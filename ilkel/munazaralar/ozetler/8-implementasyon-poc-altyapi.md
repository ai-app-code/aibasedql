# Ä°mplementasyon ve PoC AltyapÄ±sÄ± - GerÃ§ek DÃ¼nya UygulamasÄ±

## ğŸ¯ Oturum OdaÄŸÄ±
**"Kavramsal tasarÄ±mdan gerÃ§ek dÃ¼nya implementasyonuna geÃ§iÅŸ - Teknoloji, framework ve araÃ§ seÃ§imleri"**

Bu oturum, Ã¶nceki iki oturumda oluÅŸturulan kavramsal Ã§erÃ§eveyi (CAS, Decay, Confidence Weight, Î³, N_eff, BCD, KD) gerÃ§ek dÃ¼nyada uygulanabilir bir sisteme dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r. ArtÄ±k teknoloji, framework ve algoritma isimleri kullanÄ±labilir.

## ğŸ” Oturumda Ele AlÄ±nan Eksik YÃ¶nler

### 1. Meta-Ã–ÄŸrenme DerinliÄŸi
**Soru:** Fonksiyon ÅŸekli (tanh vs sigmoid vs linear) ve loss tipi meta-seviyede nasÄ±l Ã¶ÄŸrenilir?

### 2. Zaman BazlÄ± Ã‡apraz BaÄŸÄ±mlÄ±lÄ±k
**Soru:** AynÄ± gÃ¼n/lig Ã§apraz etkileri (teknik direktÃ¶r, hava durumu) portfÃ¶y korelasyonuna nasÄ±l entegre edilir?

### 3. Rollback ve GÃ¼venlik SÄ±nÄ±rlarÄ±
**Soru:** ROI -2% rollback ne kadar geriye gider? Sistem "kÄ±rmÄ±zÄ± alarm" moduna ne zaman geÃ§er?

### 4. Performans Ä°zleme ve CanlÄ± Adaptasyon
**Soru:** Sistem gerÃ§ek zamanlÄ± backtest ve A/B testing ile nasÄ±l kendi kararlarÄ±nÄ± valide eder?

## ğŸ—ï¸ 1. ÃœÃ§ KatmanlÄ± ModÃ¼ler Mimari

### Kritik Karar: Asimetrik Loss Ã‡atÄ±ÅŸmasÄ± Ã‡Ã¶zÃ¼mÃ¼

**Ã‡atÄ±ÅŸma:** Alfa (XGBoost Quantile Regression) vs Epsilon (TensorFlow Probability)
**Ã‡Ã¶zÃ¼m:** Kappa'nÄ±n modÃ¼ler katman fÃ¼zyonu

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LAYER 1: LightGBM-Quantile (Preprocessing)    â”‚
â”‚  â†’ CAS varyans daraltma, feature extraction     â”‚
â”‚  â†’ q_dynamic (0.6-0.9) output to Layer 2       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  LAYER 2: HyperNetworks (Core)                  â”‚
â”‚  â†’ Dinamik aktivasyon: tanh/sigmoid blend       â”‚
â”‚  â†’ q_dynamic-aware loss: max(q*e, (q-1)*e)     â”‚
â”‚  â†’ PyTorch Lightning + Interval Score Loss      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  LAYER 3: BNN Uncertainty (Post-Processing)     â”‚
â”‚  â†’ MC-Dropout epistemic uncertainty             â”‚
â”‚  â†’ CAS_final = CAS * (1 - uncertainty_factor)   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  INFRA: Ray/MLflow (Training) + Triton (Serving)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Layer 1: LightGBM-Quantile (Preprocessing)

**Teknoloji:** LightGBM (Dart mode) + Optuna
**AmaÃ§:** CAS varyans daraltma, hÄ±zlÄ± feature extraction

```python
import lightgbm as lgb

lgb_model = lgb.train(
    params={
        "objective": "quantile",
        "alpha": 0.7,  # Asimetrik risk profili
        "boosting_type": "dart"
    },
    train_data,
    num_boost_round=200
)

# Dinamik q deÄŸeri Ã§Ä±ktÄ±sÄ±
q_dynamic = lgb_model.predict(X)  # 0.6-0.9 aralÄ±ÄŸÄ±
```

**Trade-off:** %15 latency artÄ±ÅŸÄ±, async inference ile yÃ¶netilir

### Layer 2: HyperNetworks (Core)

**Teknoloji:** PyTorch + PyTorch Lightning
**AmaÃ§:** Dinamik aktivasyon fonksiyonu Ã¶ÄŸrenme

```python
class QuantileHyperNet(nn.Module):
    def forward(self, x, epsilon):
        # Dinamik aÄŸÄ±rlÄ±klar
        weights = self.hyper_net(x)
        
        # Risk iÅŸtahÄ± (q) dinamik ayarlama
        q_dynamic = torch.sigmoid(self.risk_head(x))  # 0.5-1.0
        
        # Asimetrik Quantile Loss
        # max(q*error, (q-1)*error)
        
        # MTGP epsilon cezasÄ±
        base = 0.4 + 0.6 * torch.tanh(self.kappa * x.momentum * x.vol)
        conf_w = torch.clamp(base * (1 - 0.5 * epsilon), 0.4, 1.0)
        
        return weights, q_dynamic, conf_w
```

**Stabilite:** Meta-SGD + Gradient Clipping

```python
# Meta-SGD: Her parametre iÃ§in ayrÄ± learning rate
w_new = w - alpha * (grad_quantile + lambda_reg * grad_entropy)

# Gradient Clipping
torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
```

**Trade-off:** %25 VRAM artÄ±ÅŸÄ±, FSDP ile yÃ¶netilir

### Layer 3: BNN Uncertainty (Post-Processing)

**Teknoloji:** Pyro-PPL (Bayesian Neural Networks)
**AmaÃ§:** Epistemic uncertainty (bilinmeyen bilinmeyenler)

```python
import pyro

class BNNWrapper(nn.Module):
    def forward(self, x):
        # MC-Dropout ile uncertainty
        predictions = []
        for _ in range(20):  # 20 sample
            pred = self.model(x)
            predictions.append(pred)
        
        mean = torch.mean(torch.stack(predictions), dim=0)
        uncertainty = torch.std(torch.stack(predictions), dim=0)
        
        # CAS'a uncertainty faktÃ¶rÃ¼ uygula
        CAS_final = CAS * (1 - uncertainty_factor)
        
        return CAS_final
```

**Trade-off:** %10 latency artÄ±ÅŸÄ±, MC-Dropout sample=20 ile optimize

## ğŸŒ 2. Zaman BazlÄ± Ã‡apraz BaÄŸÄ±mlÄ±lÄ±k

### PyTorch Geometric Temporal (TGN)

**Teknoloji:** PyTorch Geometric Temporal
**AmaÃ§:** Lig topolojisi ve momentum transferi

```python
from torch_geometric_temporal.nn.recurrent import A3TGCN

# Node: TakÄ±mlar, Edge: MaÃ§lar/Ortak KoÅŸullar
model = A3TGCN(
    in_channels=features,
    out_channels=conf_w,
    periods=5  # 5 maÃ§ geÃ§miÅŸi
)
```

**GerekÃ§e:** Standart RNN'ler topolojik (lig/rakip) iliÅŸkileri kaÃ§Ä±rÄ±r

### Multi-Task Gaussian Processes (MTGP)

**Teknoloji:** GPy (Multi-Task GP Kernel)
**AmaÃ§:** FarklÄ± ligler arasÄ± bilgi transferi

```python
import GPy

# 5 lig iÃ§in MTGP
kernel = GPy.kern.MTGPKernel(input_dim=3, num_tasks=5)
mtgp_model = GPy.models.MTGRegression(X_lig, Y_lig, kernel)
```

**Sorun:** O(nÂ³) karmaÅŸÄ±klÄ±k â†’ CanlÄ± akÄ±ÅŸta gecikme riski

**Ã‡Ã¶zÃ¼m:** Approximate MTGP (Sparse Precision Matrix)

```python
from scipy import sparse

# Low-rank approximation (r=10)
# O(nÂ³) â†’ O(nÂ·rÂ²)
precision_sparse = L @ L.T  # Cholesky low-rank
mtgp_posterior = y_train_new @ precision_sparse @ X_new
```

**Trade-off:** %5 accuracy kaybÄ±, <50ms gecikme hedefine ulaÅŸÄ±lÄ±r

### Lambda Architecture (Batch + Speed Layer)

**Teknoloji:** Ray (Batch) + Apache Flink (Speed) + Redis (Feature Store)

```python
# Batch Layer (Ray): 30dk'da bir MTGP eÄŸitimi
# Kovaryans matrislerini Redis'e yaz
ray_mtgp_train() â†’ redis.set("lig_cov_v{timestamp}", cov_matrix)

# Speed Layer (Flink): AnlÄ±k event iÅŸleme
# Redis'ten gÃ¼ncel matrisleri Ã§ek
flink_stream.map(lambda event: 
    redis.get("lig_cov_v_current") + event
)
```

**GerekÃ§e:** O(nÂ³) maliyetini canlÄ± akÄ±ÅŸtan izole eder

### Real-Time Event Processing

**Teknoloji:** Redis Streams + Apache Flink

```python
# MaÃ§-Ã¶ncesi koÅŸullarÄ± Redis Stream'e ekle
stream.add_event("match_4762", {
    "weather": "rain_heavy",
    "manager_change_days": 3,
    "rest_days": 2,
    "lig": "premier_league"
})

# Flink ile real-time correlation
def cross_dependency_rules(event):
    if event["manager_change_days"] < 7:
        gamma_adj = 0.15  # EÅŸgÃ¼dÃ¼m kaydÄ±rma
    if event["weather"] == "rain_heavy":
        Decay_adj = 0.85  # SÃ¶nÃ¼mleme kaymasÄ±
    
    return gamma_adj, Decay_adj
```

**Trade-off:** Ek infrastructure maliyeti, <100ms gecikme ile adaptasyon

## ğŸ›¡ï¸ 3. Rollback ve GÃ¼venlik SÄ±nÄ±rlarÄ±

### Circuit Breaker MekanizmasÄ±

**Teknoloji:** Kubernetes HPA + Evidently (Drift Detection)

```yaml
# K8s Circuit Breaker Config
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: bettingsystem-circuitbreaker
spec:
  minReplicas: 3
  maxReplicas: 15
  metrics:
  - type: External
    external:
      metric:
        name: bettingsystem_p_shift
      target:
        type: Value
        value: "25"  # p_shift > 0.25 tetikleyici
```

### KÄ±rmÄ±zÄ± Alarm Seviyeleri

| p_shift | ROI DÃ¼ÅŸÃ¼ÅŸÃ¼ | Aksiyon |
|---------|------------|---------|
| > 0.25 | - | Flink topology durdur, shadow mode |
| > 0.40 | - | K8s pod deployment durdur |
| > 0.60 | < -2.5% | **KÄ±rmÄ±zÄ± Alarm:** TÃ¼m pipeline cold start |

### Rollback Stratejisi

**Teknoloji:** MLflow Model Registry + Redis Dual-Key Versioning

```python
# ROI -2% ve p_BCD > 0.92 tetiklendiÄŸinde
if ROI < -0.02 and p_BCD > 0.92:
    # Model Registry'den T-2 hafta checkpoint'e rollback
    model = mlflow.pyfunc.load_model(f"models:/betting-system/T-2weeks")
    
    # Redis Key Switch (Zero-Downtime)
    redis.set("active_model_key", "lig_cov_v_safe")  # T-2 hafta
    
    # Parametreler
    lambda_multiplier = 0  # Bahis durdur
    gamma_hysteresis += 0.03
    Hard_Cap = H0 * min(1, N_eff/K) / 2
    CAS_threshold += 0.5 * sigma
```

### State Funnels (GeÃ§iÅŸ GÃ¼venliÄŸi)

```python
# Eski (safe) ve yeni (current) modeli 10 saniye paralel izle
def state_funnel_check(pred_current, pred_safe):
    diff = abs(pred_current - pred_safe)
    
    if diff > 0.15:
        # Parametre ÅŸoku riski
        return "ABORT_SWITCH"
    else:
        return "CONFIRM_SWITCH"
```

## ğŸ“Š 4. Performans Ä°zleme ve CanlÄ± Adaptasyon

### 3-Stage Deployment Gate

**Teknoloji:** MLflow + Kubeflow Pipelines

```python
def deployment_gate(metrics, stage="canary"):
    thresholds = {
        "shadow": {
            "sharpe": 0.5,
            "sortino": 0.8,
            "var95": 15
        },
        "canary": {
            "sharpe": 0.7,
            "sortino": 1.0,
            "var95": 10
        },
        "progressive": {
            "sharpe": 0.8,
            "sortino": 1.2,
            "var95": 8
        }
    }
    
    return all(metrics[k] >= v for k, v in thresholds[stage].items())
```

### Shadow Testing

**Teknoloji:** Multi-Armed Bandit (Thompson Sampling)

```python
# %10 trafik ile shadow testing
def shadow_test(model_current, model_safe, input_data):
    pred_current = model_current(input_data)
    pred_safe = model_safe(input_data)
    
    # Thompson Sampling ile model seÃ§imi
    if thompson_sample() < 0.1:
        return pred_current  # Yeni model
    else:
        return pred_safe  # GÃ¼venli model
```

### Monitoring Stack

**Teknoloji:** Prometheus + Grafana + Evidently + Great Expectations

```yaml
# Helm values.yaml - Monitoring
monitoring:
  prometheus:
    enabled: true
    serviceMonitor:
      interval: 30s
  grafana:
    enabled: true
    dashboards:
      - name: "Betting System ROI"
      - name: "Model Drift Detection"
  evidently:
    enabled: true
    drift_threshold: 0.3
```

## ğŸ’¾ 5. MTGP Accuracy KaybÄ± ve ROI YÃ¶netimi

### Kelly SDE (Stochastic Differential Equation)

```python
def adjusted_roi(base_roi, epsilon, volatility=0.15):
    # Kelly with drift-variance adjustment
    drift = base_roi * (1 - 1.2 * epsilon)
    variance_penalty = 0.5 * volatility**2 * (1 + epsilon)
    
    return drift - variance_penalty
```

**SonuÃ§:** %5 accuracy kaybÄ± (Îµâ‰ˆ0.12) â†’ Base ROI %8 ise, adjusted ROI â‰ˆ %5.8 (%27.5 kayÄ±p)

### Fractional Kelly

```python
fractional_kelly = 0.75
adjusted_roi = fractional_kelly * adjusted_roi_base
```

**GerekÃ§e:** %27.5 kayÄ±p â†’ %20'ye dÃ¼ÅŸer

### Epsilon-Aware Scaling

```python
# Frobenius Norm ile MTGP hata Ã¶lÃ§Ã¼mÃ¼
epsilon = norm_frobenius(K, K_approx) / norm_frobenius(K)

# Volatility adjustment
vol_adj = realized_vol * (1 + 0.3 * epsilon)

# Lambda final
lambda_final = lambda_base * (target_vol / vol_adj) * (1 - 0.4 * epsilon)

# Confidence Weight adjustment
Conf_W = Conf_W * (1 - 0.5 * epsilon)

# Hard-Cap adjustment
Hard_Cap = H0 * min(1, N_eff/K) * (1 - 0.2 * epsilon)

# Corridor adjustment
Corridor_Liq = Corridor_Liq * (1 + 0.8 * epsilon)
```

**Nihai SonuÃ§:** ROI kaybÄ± %27.5 â†’ %12-%15 aralÄ±ÄŸÄ±na dÃ¼ÅŸer

## ğŸ–¥ï¸ 6. VRAM YÃ¶netimi (Meta-SGD)

### FSDP (Fully Sharded Data Parallel)

**Teknoloji:** PyTorch FSDP + CPU Offload

```python
from torch.distributed.fsdp import FullyShardedDataParallel as FSDP

# Model parÃ§alara bÃ¶lÃ¼nÃ¼r
model = FSDP(
    model,
    cpu_offload=True,  # Optimizer state CPU'ya
    auto_wrap_policy=default_auto_wrap_policy
)
```

**KazanÄ±m:** %35-45 VRAM azalma

### Activation Checkpointing

```python
from torch.utils.checkpoint import checkpoint

def forward_with_checkpoint(x):
    return checkpoint(self.layer_block, x)
```

**Trade-off:** VRAM %40 tasarruf, compute %30 artÄ±ÅŸ

### Gradient Accumulation

```python
# Effective batch size = 64 (8 micro-batches Ã— 8 accumulation)
optimizer.zero_grad()
for i in range(accumulation_steps):
    loss = model(batch[i]) / accumulation_steps
    loss.backward()
optimizer.step()
```

### Mixed Precision (FP16)

```python
from torch.cuda.amp import autocast, GradScaler

scaler = GradScaler()
with autocast():
    loss = model(input)
scaler.scale(loss).backward()
scaler.step(optimizer)
scaler.update()
```

**KazanÄ±m:** VRAM %20 tasarruf, FP16 stability

### A100 MIG (Multi-Instance GPU)

```yaml
# K8s Resource Allocation
resources:
  limits:
    nvidia.com/gpu: 2
    memory: 32Gi
  requests:
    nvidia.com/gpu: 1
    memory: 16Gi
```

- **3g.20gb instance:** EÄŸitim
- **1g.5gb instance:** Serving (Triton)

## ğŸš€ 7. Serving Optimizasyonu

### Triton Inference Server

**Teknoloji:** NVIDIA Triton + TensorRT FP16

```python
# Triton Config
dynamic_batching {
    preferred_batch_sizes: [8, 16, 32]
    max_queue_delay_microseconds: 100
}

# TensorRT FP16 Optimization
model_optimization {
    execution_accelerators {
        gpu_execution_accelerator : [ {
            name : "tensorrt"
            parameters { key: "precision_mode" value: "FP16" }
        }]
    }
}
```

**KazanÄ±m:** +%40 throughput, 2x memory compress

### Priority Queue

```python
# YÃ¼ksek confidence bahisler Ã¶ncelikli iÅŸlenir
priority = Conf_W * (1 - epsilon)

# Stream ayrÄ±mÄ±
if priority > 0.8:
    queue = "high_priority"
else:
    queue = "normal"
```

**Hedef:** p99 < 60ms latency

## ğŸ“¦ 8. Final PoC AltyapÄ±sÄ±

### Docker Compose (PoC OrtamÄ±)

```yaml
services:
  # Training Pipeline
  ray-head:
    image: rayproject/ray:2.9.0-py310
    volumes: [./configs:/configs]
  
  mlflow:
    image: mlflow/mlflow:2.7.1
    ports: ["5000:5000"]

  # Serving Pipeline  
  triton:
    image: nvcr.io/nvidia/tritonserver:24.01-py3
    deploy:
      resources:
        limits:
          nvidia.com/gpu: 1
          memory: 16Gi

  # Real-time Pipeline
  flink:
    image: flink:1.17
  
  redis:
    image: redis:7.2
    command: ["--maxmemory", "4gb"]
```

### Kubernetes Helm Chart

```yaml
# values.yaml
ray:
  head:
    resources:
      limits:
        nvidia.com/gpu: 1
        memory: 32Gi
    autoscaling:
      minWorkers: 2
      maxWorkers: 8

triton:
  replicaCount: 3
  resources:
    limits:
      nvidia.com/gpu: 1
      memory: 16Gi

flink:
  taskmanager:
    replicas: 4
    resources:
      limits:
        memory: 8Gi
        cpu: 4
```

### KÃ¼tÃ¼phane BaÄŸÄ±mlÄ±lÄ±klarÄ±

**Preprocessing:**
- `lightgbm` (Dart mode)
- `optuna` (Hyperparameter tuning)

**Core:**
- `pytorch-lightning` (Trainer)
- `torchmetrics` (Interval Score)
- `torch-geometric-temporal` (TGN)

**Uncertainty:**
- `pyro-ppl` (BNN wrapper)
- `gpytorch` (Sparse GP)
- `GPy` (MTGP)

**Serving:**
- `tritonclient`
- `ray[serve]`

**Monitoring:**
- `mlflow`
- `evidently`
- `great-expectations`

## ğŸ“Š 9. Trade-off Matrisi

| BileÅŸen | Avantaj | Maliyet | YÃ¶netim Stratejisi |
|---------|---------|---------|-------------------|
| **XGBoost Quantile** | HÄ±zlÄ± preprocessing | %15 latency | Async inference |
| **HyperNetworks** | Dinamik q adaptasyonu | %25 VRAM | Gradient Clipping + Meta-SGD |
| **BNN Uncertainty** | Tail-risk korumasÄ± | %10 latency | MC-Dropout sample=20 |
| **Approx MTGP** | O(nÂ³)â†’O(nÂ·rÂ²) | %5 acc kaybÄ± | Îµ-adaptive mod |
| **Kelly SDE** | ROI volatility kontrolÃ¼ | Fractional Kelly ile gain kaybÄ± | Fraction=0.75 optimal |
| **Meta-SGD** | Stabil asimetrik Ã¶ÄŸrenme | %25 VRAM | FSDP+CPU-offload |
| **Triton FP16** | +%40 throughput | Inference precision | Calibrated |

## ğŸ¯ Kritik BaÅŸarÄ± FaktÃ¶rleri

### Accuracy vs Latency
- âœ… Approximate MTGP: %5 accuracy kaybÄ± â†’ <50ms gecikme
- âœ… 3 KatmanlÄ± Mimari: Preprocessing + Core + Post-processing
- âœ… Lambda Architecture: Batch (Ray) + Speed (Flink)

### ROI Koruma
- âœ… Kelly SDE: Drift-variance adjustment
- âœ… Fractional Kelly (0.75): %27.5 â†’ %20 kayÄ±p
- âœ… Epsilon-aware scaling: %20 â†’ %12-15 kayÄ±p

### VRAM Optimizasyonu
- âœ… FSDP + CPU-offload: %35-45 azalma
- âœ… Activation checkpointing: %40 tasarruf
- âœ… TensorRT FP16: 2x memory compress
- âœ… A100 MIG: 3g.20gb (train) + 1g.5gb (serve)

### GÃ¼venlik ve Stabilite
- âœ… Circuit Breaker: p_shift > 0.25/0.40/0.60
- âœ… Rollback: T-2 hafta checkpoint
- âœ… State Funnels: Parametre ÅŸoku Ã¶nleme
- âœ… 3-Stage Gate: Shadow â†’ Canary â†’ Progressive

## ğŸš€ SonuÃ§

Bu oturum, kavramsal tasarÄ±mÄ± gerÃ§ek dÃ¼nya implementasyonuna dÃ¶nÃ¼ÅŸtÃ¼rdÃ¼:

1. âœ… **3 KatmanlÄ± Mimari:** LightGBM + HyperNetworks + BNN
2. âœ… **Ã‡apraz BaÄŸÄ±mlÄ±lÄ±k:** TGN + MTGP + Flink/Redis
3. âœ… **GÃ¼venlik:** Circuit Breaker + Rollback + State Funnels
4. âœ… **Performans:** Shadow Testing + 3-Stage Gate + Monitoring
5. âœ… **ROI Koruma:** Kelly SDE + Fractional Kelly + Îµ-scaling
6. âœ… **VRAM YÃ¶netimi:** FSDP + Checkpointing + FP16 + MIG
7. âœ… **Serving:** Triton FP16 + Dynamic Batching + Priority Queue

**Nihai Hedefler:**
- ROI kaybÄ±: %12-15 (MTGP %5 acc kaybÄ±na raÄŸmen)
- Latency: p99 < 60ms
- VRAM: 16Gi (serving), 32Gi (training)
- Throughput: +%40 (TensorRT FP16)

