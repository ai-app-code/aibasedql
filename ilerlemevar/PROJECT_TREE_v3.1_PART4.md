# ğŸ—ï¸ SUPERBET GENESIS v3.1 - PROJE TREE PART 4
## Strategy, Risk, Monitoring, Security, Data Quality (4+ Seviye Derinlik)

---

```
superbet-genesis/ (devam)
â”‚
â”œâ”€â”€ ğŸ“ strategy/
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ coupon_engine/
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ integer_programming.py
â”‚   â”‚   â”‚   â”œâ”€â”€ class OptimalCouponCombinator:
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__(predictions, max_coupons=5, risk_aversion=0.1):
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ self.predictions = predictions
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ self.max_coupons = max_coupons
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ self.lambda_ = risk_aversion
â”‚   â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ solve_optimal_mix(timeout_ms=100) -> List[Coupon]:
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ """
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ Decision Variables: x[i,j] âˆˆ {0,1}
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ Objective: max Î£ E[Return] - Î» Ã— Î£ Risk
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ Constraints:
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€   1. Î£_j x[i,j] <= 1  (each prediction in max 1 coupon)
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€   2. Correlation[j] <= threshold
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€   3. Î£_j Stake[j] <= risk_budget
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ """
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ problem = pulp.LpProblem("CouponOptimization", pulp.LpMaximize)
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ # Binary decision variables
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ x = {(i,j): pulp.LpVariable(f"x_{i}_{j}", cat='Binary')
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚       for i in range(len(predictions)) for j in range(max_coupons)}
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ # Objective function
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ problem += sum(expected_returns) - self.lambda_ * sum(risks)
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ # Constraints
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ [add_constraint for each prediction]
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ problem.solve(pulp.PULP_CBC_CMD(msg=0, timeLimit=timeout_ms/1000))
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ return self.extract_coupons(x)
â”‚   â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ _calculate_expected_return(coupon_vars, j) -> float
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ _calculate_risk(coupon_vars, j) -> float
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ extract_coupons(x) -> List[Coupon]
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â””â”€â”€ IP_TIMEOUT_MS = 100
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ greedy_optimizer.py
â”‚   â”‚   â”‚   â”œâ”€â”€ class GreedyCouponOptimizer:
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__(predictions, max_coupon_size=10):
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ optimize(market_context) -> List[Coupon]:
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ # Sort predictions by expected value
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ sorted_preds = sorted(predictions, key=lambda p: p.ev, reverse=True)
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ coupons = []
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ for pred in sorted_preds:
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ best_coupon = self._find_best_coupon(pred, coupons)
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ assign_to_coupon(pred, best_coupon)
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ return coupons
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ _check_correlation_constraint(coupon, new_pred) -> bool
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â””â”€â”€ GREEDY_ACCURACY_LOSS = 0.05  # ~5% vs IP
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ hybrid_optimizer.py
â”‚   â”‚   â”‚   â””â”€â”€ class HybridCouponOptimizer:
â”‚   â”‚   â”‚       â”œâ”€â”€ __init__(ip_optimizer, greedy_optimizer, threshold=10):
â”‚   â”‚   â”‚       â”œâ”€â”€ optimize(predictions, market_context) -> List[Coupon]:
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ n = len(predictions)
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ if n <= self.threshold:
â”‚   â”‚   â”‚       â”‚   â”‚   â”œâ”€â”€ logger.info(f"Using IP for {n} predictions")
â”‚   â”‚   â”‚       â”‚   â”‚   â””â”€â”€ return self.ip_optimizer.solve_optimal_mix()
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ else:
â”‚   â”‚   â”‚       â”‚   â”‚   â”œâ”€â”€ logger.info(f"Using Greedy for {n} predictions (IP timeout risk)")
â”‚   â”‚   â”‚       â”‚   â”‚   â””â”€â”€ return self.greedy_optimizer.optimize(market_context)
â”‚   â”‚   â”‚       â””â”€â”€ _estimate_ip_time(n) -> float  # O(2^n) complexity warning
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ system_coupons.py
â”‚   â”‚   â”‚   â”œâ”€â”€ class SystemCouponBuilder:
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ SYSTEM_TYPES = {
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ "Trixie": {"selections": 3, "bets": 4, "structure": [3, 1]},
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ "Patent": {"selections": 3, "bets": 7, "structure": [3, 3, 1]},
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ "Yankee": {"selections": 4, "bets": 11, "structure": [6, 4, 1]},
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ "Lucky15": {"selections": 4, "bets": 15, "structure": [4, 6, 4, 1]},
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ "Lucky31": {"selections": 5, "bets": 31, "structure": "full"},
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ "Heinz": {"selections": 6, "bets": 57, "structure": "full"},
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ "SuperHeinz": {"selections": 7, "bets": 120, "structure": "full"},
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ "Goliath": {"selections": 8, "bets": 247, "structure": "full"}
â”‚   â”‚   â”‚   â”‚   â”‚   }
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ build_system(selections, system_type) -> SystemCoupon
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ if len(selections) != system_type.selections:
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ raise InvalidSystemError
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ return generate_all_combinations(selections, system_type)
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ calculate_potential_returns(system_coupon, stake) -> ReturnMatrix
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ find_break_even_winners(system_coupon) -> int
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â””â”€â”€ MIN_WINNERS = {"Trixie": 2, "Patent": 1, "Yankee": 2, ...}
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ multi_coupon_kelly.py
â”‚   â”‚   â”‚   â”œâ”€â”€ class MultiCouponKellySizer:
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ """Edward O. Thorp's Generalized Kelly: f* = Î£^(-1) Ã— Î¼"""
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__(kelly_fraction=0.25, max_single=0.20):
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ self.fraction = kelly_fraction  # Quarter Kelly for safety
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ self.max_single = max_single
â”‚   â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ calculate_optimal_stakes(coupon_portfolio) -> np.ndarray:
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ # Expected returns (excess)
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ mu = np.array([c.expected_return - 1 for c in portfolio])
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ # Covariance matrix
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ Sigma = self.estimate_coupon_covariance(portfolio)
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ # Regularize for numerical stability
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ Sigma_reg = Sigma + 0.01 * np.eye(len(portfolio))
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ # Generalized Kelly: f* = Î£^(-1) Ã— Î¼
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f_star = np.linalg.solve(Sigma_reg, mu)
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ # Apply constraints
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f_star = np.maximum(f_star, 0)  # No short selling
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ if f_star.sum() > 1.0:
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ f_star = f_star / f_star.sum()
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f_star *= self.fraction  # Quarter Kelly
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ return np.minimum(f_star, self.max_single)
â”‚   â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ estimate_coupon_covariance(portfolio) -> np.ndarray:
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ # Estimate correlation based on shared selections
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ return correlation_matrix
â”‚   â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ adjust_for_uncertainty(stakes, uncertainty) -> np.ndarray:
â”‚   â”‚   â”‚   â”‚       â””â”€â”€ return stakes * (1 - uncertainty)
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â””â”€â”€ KELLY_FRACTION = 0.25  # Conservative
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ ğŸ“„ correlation_matrix.py
â”‚   â”‚       â””â”€â”€ class CouponCorrelationEstimator:
â”‚   â”‚           â”œâ”€â”€ estimate(coupon_a, coupon_b) -> float
â”‚   â”‚           â”‚   â”œâ”€â”€ # Based on shared league, time proximity, team overlap
â”‚   â”‚           â”‚   â””â”€â”€ return correlation
â”‚   â”‚           â””â”€â”€ build_matrix(coupons) -> np.ndarray
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ strategy_plant/
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ contract.py
â”‚   â”‚   â”‚   â””â”€â”€ class StrategyPlantContract(ABC):
â”‚   â”‚   â”‚       â”œâ”€â”€ @abstractmethod
â”‚   â”‚   â”‚       â”‚   def generate_signals(predictions, market_context) -> List[Signal]
â”‚   â”‚   â”‚       â”œâ”€â”€ @abstractmethod
â”‚   â”‚   â”‚       â”‚   def get_expected_return(signal) -> float
â”‚   â”‚   â”‚       â””â”€â”€ @abstractmethod
â”‚   â”‚   â”‚           def get_risk_score(signal) -> float
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“ value_based/
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ pure_value.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ class PureValueBetting(StrategyPlantContract):
â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ generate_signals(predictions, market_context):
â”‚   â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ signals = []
â”‚   â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ for pred in predictions:
â”‚   â”‚   â”‚   â”‚       â”‚   â”‚   â”œâ”€â”€ edge = pred.prob - 1 / pred.odds
â”‚   â”‚   â”‚   â”‚       â”‚   â”‚   â”œâ”€â”€ if edge > 0:
â”‚   â”‚   â”‚   â”‚       â”‚   â”‚   â”‚   â””â”€â”€ signals.append(Signal(pred, edge))
â”‚   â”‚   â”‚   â”‚       â”‚   â””â”€â”€ return signals
â”‚   â”‚   â”‚   â”‚       â””â”€â”€ NAME = "pure_value"
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ threshold_value.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ class ThresholdValueBetting:
â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ __init__(edge_min=0.05):
â”‚   â”‚   â”‚   â”‚       â””â”€â”€ generate_signals(...):  # Only if edge > 5%
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“„ adaptive_value.py
â”‚   â”‚   â”‚       â””â”€â”€ class AdaptiveValueBetting:
â”‚   â”‚   â”‚           â”œâ”€â”€ # Adjusts edge threshold based on recent performance
â”‚   â”‚   â”‚           â””â”€â”€ _update_threshold(performance)
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“ portfolio/
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ mean_variance.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ class MeanVarianceOptimization:
â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ optimize(expected_returns, cov_matrix, risk_aversion)
â”‚   â”‚   â”‚   â”‚       â””â”€â”€ efficient_frontier(returns, cov, n_points=50)
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ risk_parity.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ class RiskParityStrategy:
â”‚   â”‚   â”‚   â”‚       â””â”€â”€ # Equal risk contribution from each position
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“„ stable_markowitz.py
â”‚   â”‚   â”‚       â””â”€â”€ class StableMarkowitzOptimizer:
â”‚   â”‚   â”‚           â”œâ”€â”€ solve(expected_returns, cov_matrix):
â”‚   â”‚   â”‚           â”‚   â”œâ”€â”€ # Check condition number
â”‚   â”‚   â”‚           â”‚   â”œâ”€â”€ if np.linalg.cond(cov_matrix) > 1e6:
â”‚   â”‚   â”‚           â”‚   â”‚   â””â”€â”€ cov_matrix += 0.01 * np.eye(n)  # Ridge
â”‚   â”‚   â”‚           â”‚   â”œâ”€â”€ # Eigenvalue thresholding
â”‚   â”‚   â”‚           â”‚   â”œâ”€â”€ eigenvalues = np.maximum(np.linalg.eigvalsh(cov_matrix), 1e-8)
â”‚   â”‚   â”‚           â”‚   â”œâ”€â”€ # Cholesky decomposition
â”‚   â”‚   â”‚           â”‚   â”œâ”€â”€ L = np.linalg.cholesky(cov_matrix)
â”‚   â”‚   â”‚           â”‚   â””â”€â”€ return scipy.linalg.solve_triangular(...)
â”‚   â”‚   â”‚           â””â”€â”€ RIDGE_LAMBDA = 0.01
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“ dynamic/
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ momentum.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ mean_reversion.py
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“„ regime_switching.py
â”‚   â”‚   â”‚       â””â”€â”€ class RegimeSwitchingStrategy:
â”‚   â”‚   â”‚           â”œâ”€â”€ detect_regime(market_data) -> Regime
â”‚   â”‚   â”‚           â””â”€â”€ switch_sub_strategy(regime) -> Strategy
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ ğŸ“ ml_based/
â”‚   â”‚       â”œâ”€â”€ ğŸ“„ ensemble_ml.py
â”‚   â”‚       â”œâ”€â”€ ğŸ“„ deep_rl.py
â”‚   â”‚       â””â”€â”€ ğŸ“„ meta_learning_strategy.py
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ allocator/
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ adaptive_allocator.py
â”‚   â”‚   â”‚   â””â”€â”€ class AdaptiveStrategyAllocator:
â”‚   â”‚   â”‚       â”œâ”€â”€ __init__(strategies, initial_alpha=10):
â”‚   â”‚   â”‚       â”‚   â””â”€â”€ self.alpha = np.ones(len(strategies)) * initial_alpha  # Dirichlet prior
â”‚   â”‚   â”‚       â”œâ”€â”€ bayesian_update(strategy_id, return_observed):
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ reward = 1 if return_observed > 0 else 0
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ self.alpha[strategy_id] += reward
â”‚   â”‚   â”‚       â”‚   â””â”€â”€ return self.alpha / self.alpha.sum()
â”‚   â”‚   â”‚       â”œâ”€â”€ thompson_sampling_selection() -> int:
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ sampled_probs = np.random.dirichlet(self.alpha)
â”‚   â”‚   â”‚       â”‚   â””â”€â”€ return np.argmax(sampled_probs)
â”‚   â”‚   â”‚       â””â”€â”€ get_optimal_allocation() -> np.ndarray
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ ğŸ“„ ab_testing.py
â”‚   â”‚       â””â”€â”€ class BayesianABTester:
â”‚   â”‚           â”œâ”€â”€ test(strategy_a_results, strategy_b_results) -> ABTestResult
â”‚   â”‚           â”‚   â”œâ”€â”€ posterior_a = beta.rvs(1 + successes_a, 1 + failures_a)
â”‚   â”‚           â”‚   â”œâ”€â”€ posterior_b = beta.rvs(1 + successes_b, 1 + failures_b)
â”‚   â”‚           â”‚   â””â”€â”€ return probability_of_b_better = P(posterior_b > posterior_a)
â”‚   â”‚           â””â”€â”€ min_sample_size(effect_size, power=0.8) -> int
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ execution/
â”‚       â”œâ”€â”€ ğŸ“„ bet_executor.py
â”‚       â”‚   â””â”€â”€ class VirtualBetExecutor:
â”‚       â”‚       â”œâ”€â”€ execute(signal, stake) -> Bet
â”‚       â”‚       â”‚   â”œâ”€â”€ # Virtual execution (paper trading)
â”‚       â”‚       â”‚   â””â”€â”€ return Bet(id, match_id, selection, stake, odds, timestamp)
â”‚       â”‚       â””â”€â”€ get_execution_report() -> ExecutionReport
â”‚       â”‚
â”‚       â”œâ”€â”€ ğŸ“„ position_tracker.py
â”‚       â”‚   â””â”€â”€ class PositionTracker:
â”‚       â”‚       â”œâ”€â”€ open_position(bet: Bet)
â”‚       â”‚       â”œâ”€â”€ close_position(bet_id, result)
â”‚       â”‚       â”œâ”€â”€ get_open_positions() -> List[Position]
â”‚       â”‚       â””â”€â”€ get_exposure() -> Exposure
â”‚       â”‚
â”‚       â””â”€â”€ ğŸ“„ pnl_calculator.py
â”‚           â””â”€â”€ class PnLCalculator:
â”‚               â”œâ”€â”€ calculate_realized_pnl(closed_positions) -> float
â”‚               â”œâ”€â”€ calculate_unrealized_pnl(open_positions, current_odds) -> float
â”‚               â””â”€â”€ get_pnl_report(period) -> PnLReport
â”‚
â”œâ”€â”€ ğŸ“ risk/
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ metrics/
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ var.py
â”‚   â”‚   â”‚   â””â”€â”€ class ValueAtRisk:
â”‚   â”‚   â”‚       â”œâ”€â”€ calculate(returns, confidence=0.95) -> float:
â”‚   â”‚   â”‚       â”‚   â””â”€â”€ return np.percentile(returns, (1 - confidence) * 100)
â”‚   â”‚   â”‚       â”œâ”€â”€ historical_var(returns, window=252)
â”‚   â”‚   â”‚       â””â”€â”€ parametric_var(returns, confidence=0.95)
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ cvar.py
â”‚   â”‚   â”‚   â””â”€â”€ class ConditionalVaR:
â”‚   â”‚   â”‚       â”œâ”€â”€ calculate(returns, var_threshold) -> float:
â”‚   â”‚   â”‚       â”‚   â””â”€â”€ return np.mean(returns[returns <= var_threshold])
â”‚   â”‚   â”‚       â””â”€â”€ expected_shortfall(returns, confidence=0.95)
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ max_drawdown.py
â”‚   â”‚   â”‚   â””â”€â”€ class MaxDrawdown:
â”‚   â”‚   â”‚       â”œâ”€â”€ calculate(equity_curve) -> float:
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ peak = np.maximum.accumulate(equity_curve)
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ drawdown = (equity_curve - peak) / peak
â”‚   â”‚   â”‚       â”‚   â””â”€â”€ return np.min(drawdown)
â”‚   â”‚   â”‚       â””â”€â”€ get_drawdown_duration(equity_curve) -> int  # days
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ sharpe.py
â”‚   â”‚   â”‚   â””â”€â”€ class SharpeRatio:
â”‚   â”‚   â”‚       â”œâ”€â”€ calculate(returns, risk_free=0.02, periods=252) -> float:
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ excess = returns - risk_free / periods
â”‚   â”‚   â”‚       â”‚   â””â”€â”€ return np.sqrt(periods) * np.mean(excess) / np.std(excess)
â”‚   â”‚   â”‚       â””â”€â”€ annualize(sharpe, periods=252) -> float
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ sortino.py
â”‚   â”‚   â”‚   â””â”€â”€ class SortinoRatio:
â”‚   â”‚   â”‚       â””â”€â”€ calculate(returns, target=0) -> float
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ ğŸ“„ kelly.py
â”‚   â”‚       â””â”€â”€ class KellyCriterion:
â”‚   â”‚           â”œâ”€â”€ calculate(win_prob, win_odds) -> float:
â”‚   â”‚           â”‚   â”œâ”€â”€ b = win_odds - 1
â”‚   â”‚           â”‚   â”œâ”€â”€ p = win_prob
â”‚   â”‚           â”‚   â”œâ”€â”€ q = 1 - p
â”‚   â”‚           â”‚   â””â”€â”€ return (b * p - q) / b
â”‚   â”‚           â”œâ”€â”€ fractional_kelly(kelly, fraction=0.75) -> float
â”‚   â”‚           â””â”€â”€ FRACTION = 0.75  # Conservative
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ limits/
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ config.py
â”‚   â”‚   â”‚   â””â”€â”€ RISK_LIMITS = {
â”‚   â”‚   â”‚       â”œâ”€â”€ "max_single_bet": 0.05,      # 5% of bankroll
â”‚   â”‚   â”‚       â”œâ”€â”€ "max_daily_loss": 0.10,      # 10% daily loss limit
â”‚   â”‚   â”‚       â”œâ”€â”€ "max_weekly_loss": 0.20,     # 20% weekly loss limit
â”‚   â”‚   â”‚       â”œâ”€â”€ "min_odds": 1.20,
â”‚   â”‚   â”‚       â”œâ”€â”€ "max_odds": 10.0,
â”‚   â”‚   â”‚       â””â”€â”€ "max_open_bets": 10
â”‚   â”‚   â”‚   }
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ enforcer.py
â”‚   â”‚   â”‚   â””â”€â”€ class RiskLimitEnforcer:
â”‚   â”‚   â”‚       â”œâ”€â”€ check_single_bet(stake, bankroll) -> bool
â”‚   â”‚   â”‚       â”œâ”€â”€ check_daily_loss(current_loss, bankroll) -> bool
â”‚   â”‚   â”‚       â”œâ”€â”€ check_weekly_loss(current_loss, bankroll) -> bool
â”‚   â”‚   â”‚       â”œâ”€â”€ check_odds_range(odds) -> bool
â”‚   â”‚   â”‚       â”œâ”€â”€ check_open_positions(current_count) -> bool
â”‚   â”‚   â”‚       â””â”€â”€ enforce(action) -> EnforcementResult
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ ğŸ“„ margin_call.py
â”‚   â”‚       â””â”€â”€ class MarginCallSystem:
â”‚   â”‚           â”œâ”€â”€ check_margin(current_exposure, limit) -> MarginStatus
â”‚   â”‚           â”œâ”€â”€ trigger_margin_call(exposure)
â”‚   â”‚           â””â”€â”€ force_close_positions(priority_order)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ circuit_breaker/
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ base.py
â”‚   â”‚   â”‚   â””â”€â”€ class CircuitBreaker:
â”‚   â”‚   â”‚       â”œâ”€â”€ __init__(failure_threshold, timeout_seconds, fallback_fn):
â”‚   â”‚   â”‚       â”œâ”€â”€ states: [CLOSED, OPEN, HALF_OPEN]
â”‚   â”‚   â”‚       â”œâ”€â”€ call(fn, *args, **kwargs):
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ if self.state == OPEN:
â”‚   â”‚   â”‚       â”‚   â”‚   â””â”€â”€ return self.fallback_fn(*args, **kwargs)
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ try:
â”‚   â”‚   â”‚       â”‚   â”‚   â”œâ”€â”€ result = fn(*args, **kwargs)
â”‚   â”‚   â”‚       â”‚   â”‚   â””â”€â”€ self._on_success()
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ except:
â”‚   â”‚   â”‚       â”‚   â”‚   â””â”€â”€ self._on_failure()
â”‚   â”‚   â”‚       â”‚   â””â”€â”€ return result
â”‚   â”‚   â”‚       â”œâ”€â”€ _on_failure():
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ self.failure_count += 1
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ if self.failure_count >= self.threshold:
â”‚   â”‚   â”‚       â”‚   â”‚   â””â”€â”€ self.state = OPEN
â”‚   â”‚   â”‚       â””â”€â”€ _on_success(): self.failure_count = 0
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ data_plant_breaker.py
â”‚   â”‚   â”‚   â””â”€â”€ DataPlantBreaker(failure_threshold=3, timeout=30, fallback=stale_data)
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ intelligence_breaker.py
â”‚   â”‚   â”‚   â””â”€â”€ IntelligenceBreaker(threshold=2, timeout=10, fallback=studentâ†’redisâ†’ruleâ†’skip)
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ feature_store_breaker.py
â”‚   â”‚   â”‚   â””â”€â”€ FeatureStoreBreaker(threshold=5, timeout=5, fallback=compute_on_fly)
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ kafka_breaker.py
â”‚   â”‚   â”‚   â””â”€â”€ KafkaBreaker(threshold=1, backoff=exponential)
â”‚   â”‚   â””â”€â”€ ğŸ“„ state_store_breaker.py
â”‚   â”‚       â””â”€â”€ StateStoreBreaker(threshold=3, timeout=15, fallback=caffeine_lru)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ emergency/
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ hedge_api.py
â”‚   â”‚   â”‚   â””â”€â”€ class EmergencyHedgeAPI:
â”‚   â”‚   â”‚       â”œâ”€â”€ check_emergency_conditions(state) -> List[str]:
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ triggers = []
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ if open_circuit_breakers >= 3:
â”‚   â”‚   â”‚       â”‚   â”‚   â””â”€â”€ triggers.append("circuit_breaker_cascade")
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ if daily_pnl < -0.10:
â”‚   â”‚   â”‚       â”‚   â”‚   â””â”€â”€ triggers.append("daily_loss_exceeded")
â”‚   â”‚   â”‚       â”‚   â””â”€â”€ return triggers
â”‚   â”‚   â”‚       â”œâ”€â”€ execute_hedge(positions, urgency):
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ if urgency == "critical":
â”‚   â”‚   â”‚       â”‚   â”‚   â””â”€â”€ return self.execute_ioc(positions)
â”‚   â”‚   â”‚       â”‚   â””â”€â”€ return self.execute_iceberg(positions, chunk_pct=0.2)
â”‚   â”‚   â”‚       â””â”€â”€ get_hedge_cost_estimate(positions) -> float
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ ioc_order.py
â”‚   â”‚   â”‚   â””â”€â”€ class ImmediateOrCancelOrder:
â”‚   â”‚   â”‚       â””â”€â”€ execute(position) -> ExecutionResult  # Immediate close or cancel
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ iceberg_order.py
â”‚   â”‚   â”‚   â””â”€â”€ class IcebergOrder:
â”‚   â”‚   â”‚       â”œâ”€â”€ __init__(chunk_pct=0.2):  # 20% chunks
â”‚   â”‚   â”‚       â””â”€â”€ execute(position) -> List[ExecutionResult]
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ ğŸ“„ cascade_detector.py
â”‚   â”‚       â””â”€â”€ class CascadeDetector:
â”‚   â”‚           â”œâ”€â”€ detect(circuit_breakers) -> bool:
â”‚   â”‚           â”‚   â””â”€â”€ return sum(1 for cb in circuit_breakers if cb.state == OPEN) >= 3
â”‚   â”‚           â””â”€â”€ get_cascade_severity() -> int
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ recovery/
â”‚       â”œâ”€â”€ ğŸ“„ state_recovery.py
â”‚       â”‚   â””â”€â”€ class StateRecoveryManager:
â”‚       â”‚       â”œâ”€â”€ save_checkpoint(state):
â”‚       â”‚       â”‚   â”œâ”€â”€ checkpoint = {
â”‚       â”‚       â”‚   â”‚   â”œâ”€â”€ "version": self.state_version,
â”‚       â”‚       â”‚   â”‚   â”œâ”€â”€ "event_offset": kafka.current_offset(),
â”‚       â”‚       â”‚   â”‚   â”œâ”€â”€ "state": state,
â”‚       â”‚       â”‚   â”‚   â””â”€â”€ "crc32": zlib.crc32(json.dumps(state).encode())
â”‚       â”‚       â”‚   â”‚   }
â”‚       â”‚       â”‚   â””â”€â”€ self.kafka_producer.send("system.checkpoints", checkpoint)
â”‚       â”‚       â”œâ”€â”€ load_checkpoint(version=None) -> Checkpoint
â”‚       â”‚       â””â”€â”€ verify_integrity(checkpoint) -> bool
â”‚       â”‚
â”‚       â”œâ”€â”€ ğŸ“„ event_replay.py
â”‚       â”‚   â””â”€â”€ class EventReplayer:
â”‚       â”‚       â”œâ”€â”€ replay(start_offset, target_state):
â”‚       â”‚       â”‚   â”œâ”€â”€ for message in replay_consumer:
â”‚       â”‚       â”‚   â”‚   â”œâ”€â”€ if not is_event_processed(message.id):
â”‚       â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ process_event(message, target_state)
â”‚       â”‚       â”‚   â”‚   â”‚   â””â”€â”€ mark_event_processed(message.id)
â”‚       â”‚       â””â”€â”€ REPLAY_BATCH_SIZE = 1000
â”‚       â”‚
â”‚       â””â”€â”€ ğŸ“„ rolling_warm_start.py
â”‚           â””â”€â”€ class RollingWarmStartManager:
â”‚               â”œâ”€â”€ spawn_new_agent(old_weights, overlap=0.8):
â”‚               â”‚   â”œâ”€â”€ new_agent = create_agent()
â”‚               â”‚   â”œâ”€â”€ new_agent.load_weights(old_weights * overlap)
â”‚               â”‚   â””â”€â”€ return new_agent
â”‚               â””â”€â”€ OVERLAP_RATIO = 0.8  # Preserve 80% of learning
â”‚
â”œâ”€â”€ ğŸ“ monitoring/
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ prometheus/
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ metrics.py
â”‚   â”‚   â”‚   â”œâ”€â”€ # Business metrics
â”‚   â”‚   â”‚   â”œâ”€â”€ prediction_confidence = Gauge("prediction_confidence", "Model confidence")
â”‚   â”‚   â”‚   â”œâ”€â”€ action_distribution = Histogram("action_distribution", "Action buckets")
â”‚   â”‚   â”‚   â”œâ”€â”€ roi_per_hour = Gauge("roi_per_hour", "Hourly ROI")
â”‚   â”‚   â”‚   â”œâ”€â”€ # EDL specific
â”‚   â”‚   â”‚   â”œâ”€â”€ edl_alpha_sum = Gauge("edl_alpha_sum", "Dirichlet strength")
â”‚   â”‚   â”‚   â”œâ”€â”€ edl_entropy = Gauge("edl_entropy", "Evidence entropy")
â”‚   â”‚   â”‚   â”œâ”€â”€ edl_tau = Gauge("edl_tau", "Uncertainty threshold")
â”‚   â”‚   â”‚   â”œâ”€â”€ edl_skip_rate = Counter("edl_skip_rate", "Skip due to uncertainty")
â”‚   â”‚   â”‚   â”œâ”€â”€ calibration_ece = Gauge("calibration_ece", "Expected Calibration Error")
â”‚   â”‚   â”‚   â”œâ”€â”€ # Circuit breaker
â”‚   â”‚   â”‚   â”œâ”€â”€ circuit_state_change = Counter("circuit_state_change", "CB state transitions")
â”‚   â”‚   â”‚   â””â”€â”€ fallback_rate = Counter("fallback_rate", "Fallback invocations")
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ ğŸ“ rules/
â”‚   â”‚       â”œâ”€â”€ ğŸ“„ slo_alerts.yaml
â”‚   â”‚       â”‚   â”œâ”€â”€ - alert: InferenceLatencyHigh
â”‚   â”‚       â”‚   â”‚   â”œâ”€â”€ expr: histogram_quantile(0.99, inference_latency) > 0.04
â”‚   â”‚       â”‚   â”‚   â”œâ”€â”€ for: 5m
â”‚   â”‚       â”‚   â”‚   â””â”€â”€ severity: critical
â”‚   â”‚       â”‚   â”œâ”€â”€ - alert: CalibrationDegraded
â”‚   â”‚       â”‚   â”‚   â”œâ”€â”€ expr: calibration_ece > 0.05
â”‚   â”‚       â”‚   â”‚   â””â”€â”€ severity: warning
â”‚   â”‚       â”‚   â””â”€â”€ - alert: HighSkipRate
â”‚   â”‚       â”‚       â”œâ”€â”€ expr: rate(edl_skip_rate[5m]) > 0.1
â”‚   â”‚       â”‚       â””â”€â”€ severity: warning
â”‚   â”‚       â”‚
â”‚   â”‚       â””â”€â”€ ğŸ“„ risk_alerts.yaml
â”‚   â”‚           â”œâ”€â”€ - alert: DailyLossExceeded
â”‚   â”‚           â”‚   â””â”€â”€ expr: daily_pnl < -0.10
â”‚   â”‚           â””â”€â”€ - alert: CircuitBreakerCascade
â”‚   â”‚               â””â”€â”€ expr: sum(circuit_breaker_open) >= 3
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ grafana/
â”‚   â”‚   â””â”€â”€ ğŸ“ dashboards/
â”‚   â”‚       â”œâ”€â”€ ğŸ“„ overview.json
â”‚   â”‚       â”‚   â”œâ”€â”€ panels:
â”‚   â”‚       â”‚   â”‚   â”œâ”€â”€ ROI (daily, weekly, monthly)
â”‚   â”‚       â”‚   â”‚   â”œâ”€â”€ Win Rate
â”‚   â”‚       â”‚   â”‚   â”œâ”€â”€ Open Positions
â”‚   â”‚       â”‚   â”‚   â”œâ”€â”€ Circuit Breaker Status
â”‚   â”‚       â”‚   â”‚   â””â”€â”€ System Health
â”‚   â”‚       â”‚   â””â”€â”€ variables: [environment, time_range]
â”‚   â”‚       â”‚
â”‚   â”‚       â”œâ”€â”€ ğŸ“„ edl_calibration.json
â”‚   â”‚       â”‚   â”œâ”€â”€ panels:
â”‚   â”‚       â”‚   â”‚   â”œâ”€â”€ ECE over time
â”‚   â”‚       â”‚   â”‚   â”œâ”€â”€ Reliability Diagram
â”‚   â”‚       â”‚   â”‚   â”œâ”€â”€ PIT Histogram
â”‚   â”‚       â”‚   â”‚   â”œâ”€â”€ Alpha Sum Distribution
â”‚   â”‚       â”‚   â”‚   â”œâ”€â”€ Skip Rate
â”‚   â”‚       â”‚   â”‚   â””â”€â”€ Latency p50/p95/p99
â”‚   â”‚       â”‚   â””â”€â”€ thresholds: {ece: 0.05, pit_p: 0.05, latency_p99: 40ms}
â”‚   â”‚       â”‚
â”‚   â”‚       â””â”€â”€ ğŸ“„ risk_management.json
â”‚   â”‚           â”œâ”€â”€ panels:
â”‚   â”‚           â”‚   â”œâ”€â”€ VaR / CVaR
â”‚   â”‚           â”‚   â”œâ”€â”€ Max Drawdown
â”‚   â”‚           â”‚   â”œâ”€â”€ Sharpe / Sortino
â”‚   â”‚           â”‚   â”œâ”€â”€ Exposure by Market
â”‚   â”‚           â”‚   â””â”€â”€ Risk Limit Utilization
â”‚   â”‚           â””â”€â”€ alerts: integrated
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ evidently/
â”‚       â”œâ”€â”€ ğŸ“„ drift_detector.py
â”‚       â”‚   â””â”€â”€ class DriftDetector:
â”‚       â”‚       â”œâ”€â”€ detect_data_drift(reference, current) -> DriftReport
â”‚       â”‚       â”œâ”€â”€ detect_prediction_drift(reference, current) -> DriftReport
â”‚       â”‚       â””â”€â”€ DRIFT_THRESHOLD = 0.1
â”‚       â”‚
â”‚       â””â”€â”€ ğŸ“„ model_monitor.py
â”‚           â””â”€â”€ class ModelPerformanceMonitor:
â”‚               â”œâ”€â”€ track_accuracy(predictions, actuals)
â”‚               â”œâ”€â”€ track_calibration(probs, outcomes)
â”‚               â””â”€â”€ generate_report() -> EvidentlyReport
â”‚
â”œâ”€â”€ ğŸ“ security/
â”‚   â”œâ”€â”€ ğŸ“ mtls/
â”‚   â”‚   â””â”€â”€ ğŸ“„ istio_config.yaml
â”‚   â”‚       â”œâ”€â”€ PeerAuthentication:
â”‚   â”‚       â”‚   â””â”€â”€ mtls.mode: STRICT
â”‚   â”‚       â””â”€â”€ AuthorizationPolicy:
â”‚   â”‚           â””â”€â”€ rules: [allow specific service-to-service]
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ vault/
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ vault_config.hcl
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ app_role.py
â”‚   â”‚   â”‚   â””â”€â”€ class VaultAppRole:
â”‚   â”‚   â”‚       â”œâ”€â”€ authenticate() -> Token
â”‚   â”‚   â”‚       â””â”€â”€ get_secret(path) -> Dict
â”‚   â”‚   â””â”€â”€ ğŸ“„ agent_sidecar.yaml
â”‚   â”‚       â””â”€â”€ # Vault Agent Injector config
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ spiffe/
â”‚       â””â”€â”€ ğŸ“„ workload_identity.py
â”‚           â””â”€â”€ class SpiffeIdentity:
â”‚               â”œâ”€â”€ get_svid() -> SVID
â”‚               â””â”€â”€ validate_peer(svid) -> bool
â”‚
â””â”€â”€ ğŸ“ data_quality/
    â”œâ”€â”€ ğŸ“ great_expectations/
    â”‚   â”œâ”€â”€ ğŸ“ expectations/
    â”‚   â”‚   â”œâ”€â”€ ğŸ“„ match_data_suite.json
    â”‚   â”‚   â”‚   â”œâ”€â”€ expect_column_to_exist: ["match_id", "kickoff", "home_team"]
    â”‚   â”‚   â”‚   â”œâ”€â”€ expect_column_values_to_not_be_null: ["match_id"]
    â”‚   â”‚   â”‚   â””â”€â”€ expect_column_values_to_be_between: {"minute": [0, 120]}
    â”‚   â”‚   â””â”€â”€ ğŸ“„ odds_data_suite.json
    â”‚   â”‚       â”œâ”€â”€ expect_column_values_to_be_greater_than: {"odds": 1.0}
    â”‚   â”‚       â””â”€â”€ expect_table_row_count_to_be_between: [1, 1000000]
    â”‚   â”‚
    â”‚   â””â”€â”€ ğŸ“„ checkpoints/
    â”‚       â””â”€â”€ ğŸ“„ hourly_validation.yml
    â”‚
    â””â”€â”€ ğŸ“ dbt/
        â”œâ”€â”€ ğŸ“„ dbt_project.yml
        â”œâ”€â”€ ğŸ“ models/
        â”‚   â”œâ”€â”€ ğŸ“ staging/
        â”‚   â”‚   â””â”€â”€ stg_matches.sql
        â”‚   â”œâ”€â”€ ğŸ“ intermediate/
        â”‚   â”‚   â””â”€â”€ int_team_form.sql
        â”‚   â””â”€â”€ ğŸ“ marts/
        â”‚       â””â”€â”€ fct_predictions.sql
        â”‚
        â””â”€â”€ ğŸ“ tests/
            â”œâ”€â”€ freshness_test.sql
            â”‚   â””â”€â”€ # data_age < 30 seconds
            â””â”€â”€ coverage_test.sql
                â””â”€â”€ # coverage > 95%
```

---

## ğŸ“Š NÄ°HAÄ° Ä°STATÄ°STÄ°KLER

| Kategori | SayÄ± |
|----------|------|
| **Toplam KlasÃ¶r** | ~200 |
| **Toplam Dosya** | ~500+ |
| **Python ModÃ¼lleri** | ~300 |
| **Java DosyalarÄ±** | ~20 |
| **Protobuf Schemas** | 4 |
| **Terraform ModÃ¼lleri** | 6 |
| **Helm Charts** | 4 |
| **Grafana Dashboards** | 6 |
| **Prometheus Rules** | 10+ |
| **GE Expectation Suites** | 4 |
| **dbt Models** | 10+ |

---

## ğŸ”— ANA DOSYALAR Ã–ZET

| Dosya | Ä°Ã§erik |
|-------|--------|
| `PROJECT_TREE_v3.1.md` | Infrastructure (GitHub, ArgoCD, Terraform, Helm) |
| `PROJECT_TREE_v3.1_PART2.md` | Services (data-plant, stream-processor, feature-store, api-gateway) |
| `PROJECT_TREE_v3.1_PART3.md` | ML (models, agents, decision) |
| `PROJECT_TREE_v3.1_PART4.md` | Strategy, Risk, Monitoring, Security, Data Quality |

---

**Versiyon:** SUPERBET GENESIS v3.1 Complete Project Structure  
**Tarih:** 04.01.2026  
**Referans:** bettingenesis-v3.1.md
