# ðŸ—ï¸ SUPERBET GENESIS v3.1 - PROJE TREE PART 3
## ML KatmanÄ± (4+ Seviye Derinlik)

---

```
superbet-genesis/ (devam)
â”‚
â”œâ”€â”€ ðŸ“ ml/
â”‚   â”‚
â”‚   â”œâ”€â”€ ðŸ“ models/
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ðŸ“ layer1_lightgbm/
â”‚   â”‚   â”‚   â”œâ”€â”€ ðŸ“„ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ðŸ“„ model.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ class LightGBMQuantileModel:
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__(config: LightGBMConfig):
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ objective: "quantile"
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ alpha: 0.7  # Asimetrik risk
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ boosting_type: "dart"
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ num_boost_round: 200
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ train(X, y, eval_set, early_stopping_rounds=50)
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ predict(X) -> np.ndarray
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ returns: quantile predictions
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ predict_with_variance(X) -> Tuple[np.ndarray, np.ndarray]
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ predictions: point estimates
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ variance: CAS varyans daraltma iÃ§in
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ get_feature_importance() -> Dict[str, float]
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ save(path: str)
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ load(path: str) -> LightGBMQuantileModel
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ FEATURE_COLUMNS: List[str] = [
â”‚   â”‚   â”‚   â”‚       "home_form", "away_form", "h2h_score", "home_xg_avg",
â”‚   â”‚   â”‚   â”‚       "away_xg_avg", "goal_diff", "league_position_diff", ...
â”‚   â”‚   â”‚   â”‚   ]
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ ðŸ“„ features.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ class FeatureEngineer:
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ compute_form_features(match, history) -> FormFeatures
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ last_5_results: [W, W, D, L, W]
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ points_last_5: int
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ goals_scored_last_5: int
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ goals_conceded_last_5: int
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ compute_h2h_features(team_a, team_b, n_matches=10)
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ team_a_wins: int
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ team_b_wins: int
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ draws: int
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ avg_goals: float
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ compute_league_features(team, league)
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ position: int
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ points_per_game: float
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ goal_difference: int
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ build_feature_vector(match) -> np.ndarray
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ FEATURE_CACHE_TTL = 3600  # 1 hour
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ ðŸ“„ quantile_config.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ @dataclass
â”‚   â”‚   â”‚   â”‚   â”‚   class LightGBMConfig:
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ objective: str = "quantile"
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ alpha: float = 0.7
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ boosting_type: str = "dart"
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ learning_rate: float = 0.05
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ num_leaves: int = 31
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ max_depth: int = 6
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ feature_fraction: float = 0.8
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ bagging_fraction: float = 0.8
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ lambda_l1: float = 0.1
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ lambda_l2: float = 0.1
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ min_data_in_leaf: int = 20
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ DYNAMIC_QUANTILE_RANGE = (0.6, 0.9)  # Adaptive Î±
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â””â”€â”€ ðŸ“„ cas_variance.py
â”‚   â”‚   â”‚       â””â”€â”€ class CASVarianceReducer:
â”‚   â”‚   â”‚           â”œâ”€â”€ __init__(target_variance: float = 0.1):
â”‚   â”‚   â”‚           â”œâ”€â”€ reduce(predictions, raw_variance) -> reduced_variance
â”‚   â”‚   â”‚           â”‚   â”œâ”€â”€ windsorize: clip extreme values
â”‚   â”‚   â”‚           â”‚   â”œâ”€â”€ smooth: exponential moving average
â”‚   â”‚   â”‚           â”‚   â””â”€â”€ scale: normalize to target range
â”‚   â”‚   â”‚           â””â”€â”€ get_confidence_adjustment(variance) -> float
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ðŸ“ layer2_hypernetworks/
â”‚   â”‚   â”‚   â”œâ”€â”€ ðŸ“„ __init__.py
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ ðŸ“ graph_lstm/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ðŸ“„ encoder.py
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ class GraphLSTMEncoder(nn.Module):
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__(input_dim, hidden_dim, num_gnn_layers, num_lstm_layers):
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ self.gnn = GraphSAGEStack(input_dim, hidden_dim, num_gnn_layers)
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ self.attention_pool = GlobalAttentionPool(hidden_dim)
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ self.lstm = nn.LSTM(hidden_dim, hidden_dim, num_lstm_layers, bidirectional=True)
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ forward(x, edge_index, batch) -> Tuple[Tensor, Tensor]:
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ x_graph = self.gnn(x, edge_index)
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ pooled = self.attention_pool(x_graph, batch)
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ pooled_seq = pooled.view(batch_size, seq_len, -1)
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ lstm_out, (h_n, c_n) = self.lstm(pooled_seq)
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ return lstm_out, h_n
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ get_embedding(x, edge_index, batch) -> Tensor [128-dim]
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ DEFAULT_CONFIG = {"input_dim": 64, "hidden_dim": 128, "num_gnn_layers": 3}
â”‚   â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ðŸ“„ gnn_layer.py
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ class GraphSAGEStack(nn.Module):
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__(input_dim, hidden_dim, num_layers, aggregator='mean'):
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ self.convs = nn.ModuleList([SAGEConv(...) for _ in range(num_layers)])
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ forward(x, edge_index) -> Tensor
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ class TemporalGraphNetwork(nn.Module):
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__(node_dim, edge_dim, memory_dim, time_dim):
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ self.memory = TGNMemory(...)
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ self.message_passing = GraphAttention(...)
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ self.time_encoder = TimeEncoder(time_dim)
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ forward(src, dst, t, msg) -> Tuple[Tensor, Tensor]
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ update_memory(src, dst, t, msg)
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ class HeterogeneousGraphConv(nn.Module):  # FarklÄ± node/edge tipleri
â”‚   â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ node_types: ["team", "player", "match"]
â”‚   â”‚   â”‚   â”‚   â”‚       â””â”€â”€ edge_types: ["plays_for", "plays_against", "in_league"]
â”‚   â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ðŸ“„ attention_pool.py
â”‚   â”‚   â”‚   â”‚       â””â”€â”€ class GlobalAttentionPool(nn.Module):
â”‚   â”‚   â”‚   â”‚           â”œâ”€â”€ __init__(hidden_dim):
â”‚   â”‚   â”‚   â”‚           â”‚   â””â”€â”€ self.gate_nn = nn.Linear(hidden_dim, 1)
â”‚   â”‚   â”‚   â”‚           â””â”€â”€ forward(x, batch) -> Tensor
â”‚   â”‚   â”‚   â”‚               â”œâ”€â”€ gate = torch.sigmoid(self.gate_nn(x))
â”‚   â”‚   â”‚   â”‚               â””â”€â”€ return scatter_add(gate * x, batch, dim=0)
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ ðŸ“ state_space/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ðŸ“„ core.py
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ class LSTMStateSpaceCore(nn.Module):
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__(input_dim, hidden_dim, state_dim):
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ self.lstm = nn.LSTM(input_dim, hidden_dim, bidirectional=True)
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ self.state_space = StateSpaceModel(input_dim, state_dim)
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ self.cross_attn = nn.MultiheadAttention(hidden_dim*2, num_heads=8)
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ forward(x, h0=None) -> Tuple[Tensor, Tensor]:
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ lstm_out, (h_n, c_n) = self.lstm(x, h0)
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ssm_out = self.state_space(x)
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ fused, _ = self.cross_attn(lstm_out, ssm_out, ssm_out)
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ return fused, h_n
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ get_temporal_dynamics(x) -> Tensor
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ DEFAULT_CONFIG = {"hidden_dim": 256, "state_dim": 64}
â”‚   â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ðŸ“„ ssm.py
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ class StateSpaceModel(nn.Module):
â”‚   â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ __init__(input_dim, state_dim):
â”‚   â”‚   â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ self.A = nn.Parameter(torch.randn(state_dim, state_dim))
â”‚   â”‚   â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ self.B = nn.Linear(input_dim, state_dim)
â”‚   â”‚   â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ self.C = nn.Linear(state_dim, input_dim)
â”‚   â”‚   â”‚   â”‚   â”‚       â”‚   â””â”€â”€ self.D = nn.Linear(input_dim, input_dim)
â”‚   â”‚   â”‚   â”‚   â”‚       â””â”€â”€ forward(x) -> Tensor:
â”‚   â”‚   â”‚   â”‚   â”‚           â”œâ”€â”€ # x_t+1 = A @ x_t + B @ u_t
â”‚   â”‚   â”‚   â”‚   â”‚           â”œâ”€â”€ # y_t = C @ x_t + D @ u_t
â”‚   â”‚   â”‚   â”‚   â”‚           â””â”€â”€ [discretized implementation]
â”‚   â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ðŸ“„ cross_attention.py
â”‚   â”‚   â”‚   â”‚       â””â”€â”€ class CrossModalAttention(nn.Module):
â”‚   â”‚   â”‚   â”‚           â”œâ”€â”€ __init__(d_model, n_heads, dropout=0.1):
â”‚   â”‚   â”‚   â”‚           â””â”€â”€ forward(query, key_value) -> Tensor
â”‚   â”‚   â”‚   â”‚               â”œâ”€â”€ # Query: temporal features
â”‚   â”‚   â”‚   â”‚               â”œâ”€â”€ # Key/Value: graph features
â”‚   â”‚   â”‚   â”‚               â””â”€â”€ return cross_attended_features
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â””â”€â”€ ðŸ“ tft/
â”‚   â”‚   â”‚       â”œâ”€â”€ ðŸ“„ decoder.py
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ class TemporalFusionDecoder(nn.Module):
â”‚   â”‚   â”‚       â”‚   â”‚   â”œâ”€â”€ __init__(d_model, n_heads, num_quantiles=3):
â”‚   â”‚   â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ self.vsn = VariableSelectionNetwork(...)
â”‚   â”‚   â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ self.grn = GatedResidualNetwork(...)
â”‚   â”‚   â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ self.attention = InterpretableMultiHeadAttention(...)
â”‚   â”‚   â”‚       â”‚   â”‚   â”‚   â””â”€â”€ self.output = nn.Linear(d_model, num_quantiles)
â”‚   â”‚   â”‚       â”‚   â”‚   â”œâ”€â”€ forward(encoder_output, known_futures, static_context)
â”‚   â”‚   â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ selected = self.vsn(encoder_output, static_context)
â”‚   â”‚   â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ gated = self.grn(selected)
â”‚   â”‚   â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ attended, attention_weights = self.attention(gated)
â”‚   â”‚   â”‚       â”‚   â”‚   â”‚   â””â”€â”€ return self.output(attended), attention_weights
â”‚   â”‚   â”‚       â”‚   â”‚   â””â”€â”€ get_attention_weights() -> Tensor  # Interpretability
â”‚   â”‚   â”‚       â”‚   â””â”€â”€ QUANTILES = [0.1, 0.5, 0.9]
â”‚   â”‚   â”‚       â”‚
â”‚   â”‚   â”‚       â”œâ”€â”€ ðŸ“„ variable_selection.py
â”‚   â”‚   â”‚       â”‚   â””â”€â”€ class VariableSelectionNetwork(nn.Module):
â”‚   â”‚   â”‚       â”‚       â”œâ”€â”€ __init__(d_model, num_inputs, dropout=0.1):
â”‚   â”‚   â”‚       â”‚       â”‚   â”œâ”€â”€ self.flattened_grn = GRN(num_inputs * d_model, num_inputs)
â”‚   â”‚   â”‚       â”‚       â”‚   â””â”€â”€ self.single_grns = nn.ModuleList([GRN(d_model) for _ in range(num_inputs)])
â”‚   â”‚   â”‚       â”‚       â””â”€â”€ forward(inputs, context) -> Tuple[Tensor, Tensor]:
â”‚   â”‚   â”‚       â”‚           â”œâ”€â”€ # Compute variable selection weights
â”‚   â”‚   â”‚       â”‚           â”œâ”€â”€ weights = softmax(self.flattened_grn(flatten(inputs), context))
â”‚   â”‚   â”‚       â”‚           â””â”€â”€ return weighted_sum(inputs, weights), weights
â”‚   â”‚   â”‚       â”‚
â”‚   â”‚   â”‚       â””â”€â”€ ðŸ“„ interpretable_attention.py
â”‚   â”‚   â”‚           â””â”€â”€ class InterpretableMultiHeadAttention(nn.Module):
â”‚   â”‚   â”‚               â”œâ”€â”€ __init__(d_model, n_heads):
â”‚   â”‚   â”‚               â”‚   â””â”€â”€ # Single head but multiple value projections
â”‚   â”‚   â”‚               â””â”€â”€ forward(q, k, v) -> Tuple[Tensor, Tensor]:
â”‚   â”‚   â”‚                   â”œâ”€â”€ # Returns output and interpretable attention weights
â”‚   â”‚   â”‚                   â””â”€â”€ return output, attention_weights
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ðŸ“ layer3_edl/
â”‚   â”‚   â”‚   â”œâ”€â”€ ðŸ“„ __init__.py
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ ðŸ“„ evidential_head.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ class EvidentialHead(nn.Module):
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__(input_dim, num_classes=3):
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ self.fc = nn.Linear(input_dim, num_classes * 4)  # 4 Dirichlet params per class
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ self.softplus = nn.Softplus()
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ forward(x) -> Dict[str, Tensor]:
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ evidence = self.softplus(self.fc(x))  # N Ã— num_classes Ã— 4
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ alpha = evidence + 1  # Dirichlet concentration
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ probs = alpha / alpha.sum(dim=-1, keepdim=True)
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ uncertainty = self._compute_uncertainty(alpha)
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ if uncertainty.mean() > 0.4:
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ return {'action': 'skip', 'uncertainty': uncertainty}
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ return {'probs': probs, 'uncertainty': uncertainty, 'alpha': alpha}
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ _compute_uncertainty(alpha) -> Tensor:
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ S = alpha.sum(dim=-1)  # Dirichlet strength
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ K = alpha.shape[-1]   # Number of classes
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ return K / S  # Mutual information proxy
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ get_epistemic_uncertainty(alpha) -> Tensor:
â”‚   â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ # Separate aleatoric vs epistemic
â”‚   â”‚   â”‚   â”‚   â”‚       â””â”€â”€ return entropy(Dirichlet(alpha)) - expected_entropy
â”‚   â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ UNCERTAINTY_THRESHOLD = 0.4  # Ï„ > 0.4 â†’ skip
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ ðŸ“„ loss.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ def evidential_loss(pred, target, epoch, max_epochs=100, lambda_kl=0.1):
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ alpha = pred['alpha']
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ target_one_hot = F.one_hot(target, num_classes=alpha.shape[-1])
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ # Negative Log-Likelihood
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ L_nll = -torch.sum(target_one_hot * (torch.digamma(alpha) - torch.digamma(alpha.sum(-1, keepdim=True))))
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ # KL Annealing
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ annealing = min(1.0, epoch / (max_epochs * 0.1))
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ uniform_alpha = torch.ones_like(alpha)
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ L_kl = kl_divergence_dirichlet(alpha, uniform_alpha)
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ return L_nll + annealing * lambda_kl * L_kl
â”‚   â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ def kl_divergence_dirichlet(alpha, beta):
â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ # KL(Dir(Î±) || Dir(Î²))
â”‚   â”‚   â”‚   â”‚       â””â”€â”€ [standard Dirichlet KL formula]
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ ðŸ“„ calibration.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ class EDLCalibrator:
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__(temperature=1.0, prior_strength=1.0):
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ calibrate_temperature(val_probs, val_labels) -> float:
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ # Optimize temperature for calibration
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ return optimal_temperature (via L-BFGS)
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ compute_ece(probs, labels, n_bins=15) -> float:
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ # Expected Calibration Error
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ bins = np.linspace(0, 1, n_bins + 1)
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ return weighted_avg(|accuracy - confidence|)
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ pit_uniformity_test(probs, labels) -> PitResult:
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ # Probability Integral Transform
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ pit_values = compute_pit(probs, labels)
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ks_stat, p_value = stats.kstest(pit_values, 'uniform')
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ return PitResult(ks_stat, p_value, pass=p_value > 0.05)
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ reliability_diagram(probs, labels, n_bins=10) -> ReliabilityDiagram:
â”‚   â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ # Compute calibration curve
â”‚   â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ slope, intercept = linear_fit(confidence, accuracy)
â”‚   â”‚   â”‚   â”‚   â”‚       â””â”€â”€ return ReliabilityDiagram(slope, intercept)  # slope â‰ˆ 1 is ideal
â”‚   â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ @dataclass
â”‚   â”‚   â”‚   â”‚   â”‚   class CalibrationMetrics:
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ece: float  # < 0.05 is good
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ pit_p_value: float  # > 0.05 is good
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ reliability_slope: float  # â‰ˆ 1 is ideal
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ reliability_intercept: float  # â‰ˆ 0 is ideal
â”‚   â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ CALIBRATION_THRESHOLDS = {
â”‚   â”‚   â”‚   â”‚       "ece": 0.05,
â”‚   â”‚   â”‚   â”‚       "pit_p_value": 0.05,
â”‚   â”‚   â”‚   â”‚       "reliability_slope_min": 0.9,
â”‚   â”‚   â”‚   â”‚       "reliability_slope_max": 1.1
â”‚   â”‚   â”‚   â”‚   }
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ ðŸ“„ uncertainty.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ class UncertaintyGate:
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__(threshold: float = 0.4):
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ should_skip(uncertainty: Tensor) -> bool:
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ return uncertainty.mean() > self.threshold
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ get_action(uncertainty: Tensor, probs: Tensor) -> Action:
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ if uncertainty > 0.4: return Action.SKIP
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ if uncertainty > 0.3: return Action.REDUCE_STAKE
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ return Action.BET
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ compute_kelly_adjustment(uncertainty: Tensor) -> float:
â”‚   â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ # Reduce Kelly fraction based on uncertainty
â”‚   â”‚   â”‚   â”‚   â”‚       â””â”€â”€ return 1.0 - uncertainty
â”‚   â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ enum Action: [BET, REDUCE_STAKE, SKIP, HEDGE]
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â””â”€â”€ ðŸ“„ config.py
â”‚   â”‚   â”‚       â””â”€â”€ @dataclass
â”‚   â”‚   â”‚           class EDLConfig:
â”‚   â”‚   â”‚           â”œâ”€â”€ input_dim: int = 256
â”‚   â”‚   â”‚           â”œâ”€â”€ num_classes: int = 3  # [home_win, draw, away_win]
â”‚   â”‚   â”‚           â”œâ”€â”€ uncertainty_threshold: float = 0.4
â”‚   â”‚   â”‚           â”œâ”€â”€ kl_annealing_epochs: int = 10
â”‚   â”‚   â”‚           â”œâ”€â”€ prior_strength: float = 1.0
â”‚   â”‚   â”‚           â”œâ”€â”€ temperature: float = 1.0
â”‚   â”‚   â”‚           â””â”€â”€ calibration_frequency: int = 100  # batches
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ðŸ“ ensemble/
â”‚   â”‚   â”‚   â”œâ”€â”€ ðŸ“„ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ðŸ“„ ensemble_model.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ class DeepEnsemble(nn.Module):
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__(base_model_class, num_models=5, **model_kwargs):
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ self.models = nn.ModuleList([base_model_class(**model_kwargs) for _ in range(num_models)])
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ forward(x) -> Dict[str, Tensor]:
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ predictions = [model(x) for model in self.models]
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ mean_pred = torch.stack(predictions).mean(dim=0)
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ std_pred = torch.stack(predictions).std(dim=0)
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ return {'prediction': mean_pred, 'uncertainty': std_pred}
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ get_disagreement() -> Tensor:
â”‚   â”‚   â”‚   â”‚   â”‚       â””â”€â”€ return pairwise_disagreement_score
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ NUM_ENSEMBLE_MODELS = 5  # Pre-match only (too slow for live)
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â””â”€â”€ ðŸ“„ aggregator.py
â”‚   â”‚   â”‚       â””â”€â”€ class EnsembleAggregator:
â”‚   â”‚   â”‚           â”œâ”€â”€ aggregate_predictions(predictions: List[Tensor], method='mean')
â”‚   â”‚   â”‚           â”‚   â”œâ”€â”€ methods: ['mean', 'median', 'weighted_mean']
â”‚   â”‚   â”‚           â”‚   â””â”€â”€ return aggregated_prediction
â”‚   â”‚   â”‚           â””â”€â”€ compute_ensemble_uncertainty(predictions) -> Tensor
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ ðŸ“ hybrid/
â”‚   â”‚       â”œâ”€â”€ ðŸ“„ __init__.py
â”‚   â”‚       â”œâ”€â”€ ðŸ“„ pipeline.py
â”‚   â”‚       â”‚   â”œâ”€â”€ class HybridModelPipeline:
â”‚   â”‚       â”‚   â”‚   â”œâ”€â”€ __init__(layer1, layer2, layer3):
â”‚   â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ self.layer1 = layer1  # LightGBM-Quantile
â”‚   â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ self.layer2 = layer2  # HyperNetworks
â”‚   â”‚       â”‚   â”‚   â”‚   â””â”€â”€ self.layer3 = layer3  # EDL
â”‚   â”‚       â”‚   â”‚   â”œâ”€â”€ forward(raw_features, graph_data) -> HybridPrediction:
â”‚   â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ # Layer 1: Quick feature preprocessing
â”‚   â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ l1_output = self.layer1.predict_with_variance(raw_features)
â”‚   â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ # Layer 2: Deep temporal-spatial encoding
â”‚   â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ l2_output = self.layer2(l1_output.features, graph_data)
â”‚   â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ # Layer 3: Uncertainty estimation
â”‚   â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ l3_output = self.layer3(l2_output)
â”‚   â”‚       â”‚   â”‚   â”‚   â””â”€â”€ return HybridPrediction(
â”‚   â”‚       â”‚   â”‚   â”‚       probs=l3_output['probs'],
â”‚   â”‚       â”‚   â”‚   â”‚       uncertainty=l3_output['uncertainty'],
â”‚   â”‚       â”‚   â”‚   â”‚       confidence=l1_output.confidence,
â”‚   â”‚       â”‚   â”‚   â”‚       attention_weights=l2_output.attention_weights
â”‚   â”‚       â”‚   â”‚   â”‚   )
â”‚   â”‚       â”‚   â”‚   â””â”€â”€ get_layer_contributions() -> Dict[str, float]
â”‚   â”‚       â”‚   â”‚
â”‚   â”‚       â”‚   â””â”€â”€ @dataclass
â”‚   â”‚       â”‚       class HybridPrediction:
â”‚   â”‚       â”‚       â”œâ”€â”€ probs: Tensor  # [home, draw, away]
â”‚   â”‚       â”‚       â”œâ”€â”€ uncertainty: float  # Ï„
â”‚   â”‚       â”‚       â”œâ”€â”€ confidence: float
â”‚   â”‚       â”‚       â”œâ”€â”€ attention_weights: Tensor  # Interpretability
â”‚   â”‚       â”‚       â””â”€â”€ should_skip: bool  # Ï„ > 0.4
â”‚   â”‚       â”‚
â”‚   â”‚       â”œâ”€â”€ ðŸ“„ inference.py
â”‚   â”‚       â”‚   â”œâ”€â”€ class HybridInferenceService:
â”‚   â”‚       â”‚   â”‚   â”œâ”€â”€ __init__(pipeline, feast_client, redis_client):
â”‚   â”‚       â”‚   â”‚   â”œâ”€â”€ async predict(match_id: int) -> HybridPrediction:
â”‚   â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ # Fetch features from Feast
â”‚   â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ features = await self.feast_client.get_online_features(match_id)
â”‚   â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ # Fetch graph data from Milvus
â”‚   â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ graph_data = await self.get_graph_embedding(match_id)
â”‚   â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ # Run pipeline
â”‚   â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ prediction = self.pipeline(features, graph_data)
â”‚   â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ # Cache result
â”‚   â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ await self.redis_client.set(f"pred:{match_id}", prediction, ttl=30)
â”‚   â”‚       â”‚   â”‚   â”‚   â””â”€â”€ return prediction
â”‚   â”‚       â”‚   â”‚   â””â”€â”€ async batch_predict(match_ids: List[int]) -> List[HybridPrediction]
â”‚   â”‚       â”‚   â”‚
â”‚   â”‚       â”‚   â””â”€â”€ INFERENCE_TIMEOUT_MS = 40  # p99 < 40ms target
â”‚   â”‚       â”‚
â”‚   â”‚       â””â”€â”€ ðŸ“„ config.py
â”‚   â”‚           â””â”€â”€ @dataclass
â”‚   â”‚               class HybridPipelineConfig:
â”‚   â”‚               â”œâ”€â”€ layer1_config: LightGBMConfig
â”‚   â”‚               â”œâ”€â”€ layer2_config: HyperNetworkConfig
â”‚   â”‚               â”œâ”€â”€ layer3_config: EDLConfig
â”‚   â”‚               â”œâ”€â”€ use_ensemble_for_prematch: bool = True
â”‚   â”‚               â”œâ”€â”€ use_edl_for_live: bool = True
â”‚   â”‚               â””â”€â”€ max_latency_ms: int = 40
â”‚   â”‚
â”‚   â”œâ”€â”€ ðŸ“ agents/
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ðŸ“ manager/
â”‚   â”‚   â”‚   â”œâ”€â”€ ðŸ“„ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ðŸ“„ ucb_manager.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ class UCBManagerAgent:
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__(workers: List[WorkerAgent], exploration_coef=0.2):
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ self.workers = workers
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ self.c = exploration_coef
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ self.arm_stats = {w.name: ArmStats() for w in workers}
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ select_worker(state: ManagerState) -> WorkerAgent:
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ total_pulls = sum(arm.n for arm in self.arm_stats.values())
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ucb_scores = {}
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ for arm_name, arm in self.arm_stats.items():
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ exploitation = arm.q  # Average reward
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ exploration = self.c * sqrt(log(total_pulls) / (arm.n + 1))
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ucb_scores[arm_name] = exploitation + exploration
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ return self.workers[argmax(ucb_scores)]
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ update(worker_name: str, reward: float):
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ arm = self.arm_stats[worker_name]
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ arm.n += 1
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ arm.q += (reward - arm.q) / arm.n  # Incremental update
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ get_worker_performance() -> Dict[str, WorkerPerformance]
â”‚   â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ @dataclass
â”‚   â”‚   â”‚   â”‚       class ArmStats:
â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ q: float = 0.0  # Average reward
â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ n: int = 0      # Number of pulls
â”‚   â”‚   â”‚   â”‚       â””â”€â”€ history: deque = field(default_factory=lambda: deque(maxlen=10))
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ ðŸ“„ roi_history.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ class ROIHistoryTracker:
â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ __init__(maxlen=10):
â”‚   â”‚   â”‚   â”‚       â”‚   â””â”€â”€ self.history = deque(maxlen=maxlen)  # O(1) operations
â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ add(roi: float, timestamp: datetime)
â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ get_rolling_average() -> float
â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ get_trend() -> str  # "UP", "DOWN", "STABLE"
â”‚   â”‚   â”‚   â”‚       â””â”€â”€ should_reduce_risk() -> bool:
â”‚   â”‚   â”‚   â”‚           â””â”€â”€ return self.get_rolling_average() < -0.02
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ ðŸ“„ dynamic_lambda.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ class DynamicLambdaController:
â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ __init__(base_lambda=1.0, mode_multipliers=None):
â”‚   â”‚   â”‚   â”‚       â”‚   â””â”€â”€ self.mode_multipliers = mode_multipliers or {
â”‚   â”‚   â”‚   â”‚       â”‚       "COORDINATION": 1.15,
â”‚   â”‚   â”‚   â”‚       â”‚       "LEADERSHIP": 1.40,
â”‚   â”‚   â”‚   â”‚       â”‚       "NEUTRAL": 1.0
â”‚   â”‚   â”‚   â”‚       â”‚   }
â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ compute_lambda(gamma: float, roi_history: deque, avg_corr: float) -> float:
â”‚   â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ mode = self._detect_mode(gamma)
â”‚   â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ mode_mult = self.mode_multipliers[mode]
â”‚   â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ corr_adj = 1 + sqrt(avg_corr)
â”‚   â”‚   â”‚   â”‚       â”‚   â””â”€â”€ return self.base_lambda * mode_mult * corr_adj
â”‚   â”‚   â”‚   â”‚       â””â”€â”€ _detect_mode(gamma) -> str:
â”‚   â”‚   â”‚   â”‚           â”œâ”€â”€ if gamma < -0.08: return "COORDINATION"
â”‚   â”‚   â”‚   â”‚           â”œâ”€â”€ if gamma > 0.52: return "LEADERSHIP"
â”‚   â”‚   â”‚   â”‚           â””â”€â”€ return "NEUTRAL"
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â””â”€â”€ ðŸ“„ worker_selector.py
â”‚   â”‚   â”‚       â””â”€â”€ class WorkerSelector:
â”‚   â”‚   â”‚           â”œâ”€â”€ select(match_status: MatchStatus) -> WorkerType:
â”‚   â”‚   â”‚           â”‚   â”œâ”€â”€ if match_status == SCHEDULED: return PREMATCH_WORKER
â”‚   â”‚   â”‚           â”‚   â”œâ”€â”€ if match_status == LIVE: return LIVE_WORKER
â”‚   â”‚   â”‚           â”‚   â””â”€â”€ return NONE
â”‚   â”‚   â”‚           â””â”€â”€ handover_needed(old_status, new_status) -> bool
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ðŸ“ live_worker/
â”‚   â”‚   â”‚   â”œâ”€â”€ ðŸ“„ ppo_agent.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ class PPOLiveAgent:
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__(policy_network, value_network, config):
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ self.policy = policy_network  # LSTM policy
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ self.value = value_network
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ self.clip_epsilon = config.clip_epsilon  # 0.2
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ self.entropy_coef = config.entropy_coef  # 0.01
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ select_action(state: LiveState, hidden: Tensor) -> Action:
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ action_probs, new_hidden = self.policy(state, hidden)
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ # Apply CVaR constraint
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ constrained_probs = self.cvar_thompson.constrain(action_probs)
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ return sample(constrained_probs), new_hidden
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ update(trajectories: List[Trajectory]):
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ # PPO clipped objective
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ for _ in range(self.epochs):
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ratio = new_probs / old_probs
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ clipped = clip(ratio, 1-Îµ, 1+Îµ)
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ loss = -min(ratio * advantage, clipped * advantage)
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ update_parameters(loss)
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ get_hidden_state() -> Tensor  # For handover
â”‚   â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ PPO_CONFIG = {"clip_epsilon": 0.2, "epochs": 4, "batch_size": 64}
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ ðŸ“„ lstm_policy.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ class LSTMPolicyNetwork(nn.Module):
â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ __init__(state_dim, action_dim, hidden_dim=256):
â”‚   â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ self.lstm = nn.LSTM(state_dim, hidden_dim)
â”‚   â”‚   â”‚   â”‚       â”‚   â””â”€â”€ self.head = nn.Linear(hidden_dim, action_dim)
â”‚   â”‚   â”‚   â”‚       â””â”€â”€ forward(state, hidden) -> Tuple[Tensor, Tensor]:
â”‚   â”‚   â”‚   â”‚           â”œâ”€â”€ lstm_out, new_hidden = self.lstm(state, hidden)
â”‚   â”‚   â”‚   â”‚           â””â”€â”€ return softmax(self.head(lstm_out)), new_hidden
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ ðŸ“„ cvar_thompson.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ class CVaRThompsonSampler:
â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ __init__(cvar_limit=0.05):
â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ constrained_sample(priors, bankroll) -> Tuple[int, float]:
â”‚   â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ samples = [beta.rvs(Î±, Î²) for Î±, Î² in priors]
â”‚   â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ valid = [i for i, s in enumerate(samples) if percentile(s, 5) >= self.cvar_limit]
â”‚   â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ if not valid: return None, 0
â”‚   â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ best = argmax(samples[valid])
â”‚   â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ stake = min(bankroll * 0.05, bankroll * samples[best] * 0.3)
â”‚   â”‚   â”‚   â”‚       â”‚   â””â”€â”€ return best, stake
â”‚   â”‚   â”‚   â”‚       â””â”€â”€ update_priors(action, outcome)
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â””â”€â”€ ðŸ“„ action_space.py
â”‚   â”‚   â”‚       â””â”€â”€ class LiveActionSpace:
â”‚   â”‚   â”‚           â”œâ”€â”€ actions: [BET_HOME, BET_DRAW, BET_AWAY, SKIP, HEDGE, CLOSE_POSITION]
â”‚   â”‚   â”‚           â”œâ”€â”€ get_stake_range(action) -> Tuple[float, float]
â”‚   â”‚   â”‚           â””â”€â”€ is_valid(action, state) -> bool
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ðŸ“ prematch_worker/
â”‚   â”‚   â”‚   â”œâ”€â”€ ðŸ“„ dqn_agent.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ class DQNPreMatchAgent:
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__(q_network, target_network, replay_buffer, config):
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ select_action(state, epsilon) -> Action:
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ if random() < epsilon: return random_action()
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ return argmax(self.q_network(state))
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ update(batch_size=64):
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ batch = self.replay_buffer.sample(batch_size)
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ targets = r + Î³ * max(target_network(s'))
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ loss = MSE(q_network(s, a), targets)
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ sync_target_network()
â”‚   â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ DQN_CONFIG = {"gamma": 0.99, "epsilon_decay": 0.995, "target_update": 1000}
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ ðŸ“„ replay_buffer.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ class PrioritizedReplayBuffer:
â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ __init__(capacity=100000, alpha=0.6):
â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ add(state, action, reward, next_state, done, priority)
â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ sample(batch_size) -> Tuple[Batch, Weights, Indices]
â”‚   â”‚   â”‚   â”‚       â””â”€â”€ update_priorities(indices, priorities)
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â””â”€â”€ ðŸ“„ q_network.py
â”‚   â”‚   â”‚       â””â”€â”€ class QNetwork(nn.Module):
â”‚   â”‚   â”‚           â”œâ”€â”€ __init__(state_dim, action_dim, hidden_dims=[256, 128]):
â”‚   â”‚   â”‚           â””â”€â”€ forward(state) -> Tensor  # Q-values for each action
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ðŸ“ handover/
â”‚   â”‚   â”‚   â”œâ”€â”€ ðŸ“„ protocol.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ class HandoverProtocol:
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__(redis_client, timeout_seconds=5):
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ execute_handover(match_id, prematch_agent, live_agent):
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ # 1. Get final state from prematch
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ pre_state = prematch_agent.get_final_state()
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ # 2. Atomic transfer via Redis WATCH-MULTI
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ self.atomic_transfer(match_id, pre_state)
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ # 3. Initialize live agent with prematch context
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ live_agent.load_hidden_state(pre_state.hidden_state)
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ # 4. Start teacher forcing
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ self.start_teacher_forcing(live_agent, pre_state)
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ verify_handover(match_id) -> bool
â”‚   â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ HANDOVER_TIMEOUT_SECONDS = 5
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ ðŸ“„ atomic_transfer.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ class AtomicStateTransfer:
â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ transfer(redis, key, state):
â”‚   â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ # Redis WATCH-MULTI-EXEC for atomicity
â”‚   â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ pipe = redis.pipeline()
â”‚   â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ pipe.watch(key)
â”‚   â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ pipe.multi()
â”‚   â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ pipe.set(key, serialize(state))
â”‚   â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ pipe.expire(key, 300)  # 5 min TTL
â”‚   â”‚   â”‚   â”‚       â”‚   â””â”€â”€ return pipe.execute()
â”‚   â”‚   â”‚   â”‚       â””â”€â”€ rollback(redis, key, previous_state)
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ ðŸ“„ teacher_forcing.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ class TeacherForcingScheduler:
â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ __init__(initial_weight=1.0, decay_minutes=10):
â”‚   â”‚   â”‚   â”‚       â”‚   â””â”€â”€ self.weight = initial_weight  # 1.0 â†’ 0.0
â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ get_current_weight(minutes_elapsed) -> float:
â”‚   â”‚   â”‚   â”‚       â”‚   â””â”€â”€ return max(0, 1.0 - minutes_elapsed / self.decay_minutes)
â”‚   â”‚   â”‚   â”‚       â””â”€â”€ apply_forcing(live_pred, prematch_pred, weight) -> Tensor:
â”‚   â”‚   â”‚   â”‚           â””â”€â”€ return weight * prematch_pred + (1 - weight) * live_pred
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â””â”€â”€ ðŸ“„ state_snapshot.py
â”‚   â”‚   â”‚       â””â”€â”€ @dataclass
â”‚   â”‚   â”‚           class AgentStateSnapshot:
â”‚   â”‚   â”‚           â”œâ”€â”€ hidden_state: Tensor  # LSTM hidden state
â”‚   â”‚   â”‚           â”œâ”€â”€ predictions: Dict[str, float]
â”‚   â”‚   â”‚           â”œâ”€â”€ confidence: float
â”‚   â”‚   â”‚           â”œâ”€â”€ position: Optional[Position]
â”‚   â”‚   â”‚           â””â”€â”€ timestamp: datetime
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ ðŸ“ meta_learning/
â”‚   â”‚       â”œâ”€â”€ ðŸ“„ knowledge_distillation.py
â”‚   â”‚       â”‚   â”œâ”€â”€ class KnowledgeDistiller:
â”‚   â”‚       â”‚   â”‚   â”œâ”€â”€ __init__(teacher, student, temperature=2.0):
â”‚   â”‚       â”‚   â”‚   â”œâ”€â”€ distill(teacher_logits, student_logits, hard_labels, epoch, T):
â”‚   â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ w_t = 0.3 + 0.7 * sigmoid(epoch - T/2)  # 0.3â†’1.0
â”‚   â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ L_hard = cross_entropy(student_logits, hard_labels)
â”‚   â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ L_soft = kl_div(softmax(student_logits/temp), softmax(teacher_logits/temp))
â”‚   â”‚       â”‚   â”‚   â”‚   â””â”€â”€ return w_t * L_hard + (1 - w_t) * L_soft
â”‚   â”‚       â”‚   â”‚   â””â”€â”€ get_distillation_schedule(p_bcd) -> int:
â”‚   â”‚       â”‚   â”‚       â””â”€â”€ return 30 if p_bcd > 0.9 else 60  # matches
â”‚   â”‚       â”‚   â”‚
â”‚   â”‚       â”‚   â””â”€â”€ TEMPERATURE = 2.0
â”‚   â”‚       â”‚
â”‚   â”‚       â”œâ”€â”€ ðŸ“„ bcd_detector.py
â”‚   â”‚       â”‚   â””â”€â”€ class BayesianChangePointDetector:
â”‚   â”‚       â”‚       â”œâ”€â”€ __init__(prior_mean=0, prior_var=1):
â”‚   â”‚       â”‚       â”œâ”€â”€ update(observation: float) -> float:
â”‚   â”‚       â”‚       â”‚   â””â”€â”€ return p_changepoint  # [0, 1]
â”‚   â”‚       â”‚       â”œâ”€â”€ detect_regime_change(gamma_history, roi_history) -> RegimeChangeAlert:
â”‚   â”‚       â”‚       â”‚   â”œâ”€â”€ p_bcd = self.probability_of_change()
â”‚   â”‚       â”‚       â”‚   â”œâ”€â”€ gamma_slope = gradient(gamma_history, window=3)
â”‚   â”‚       â”‚       â”‚   â”œâ”€â”€ if p_bcd > 0.85 and gamma_slope < -0.1:
â”‚   â”‚       â”‚       â”‚   â”‚   â””â”€â”€ return RegimeChangeAlert.EARLY_WARNING
â”‚   â”‚       â”‚       â”‚   â”œâ”€â”€ if p_bcd > 0.92 and roi_drop > 0.15:
â”‚   â”‚       â”‚       â”‚   â”‚   â””â”€â”€ return RegimeChangeAlert.OBSERVATION_MODE
â”‚   â”‚       â”‚       â”‚   â”œâ”€â”€ if p_bcd > 0.95:
â”‚   â”‚       â”‚       â”‚   â”‚   â””â”€â”€ return RegimeChangeAlert.PHASE_RESET
â”‚   â”‚       â”‚       â”‚   â””â”€â”€ return RegimeChangeAlert.NORMAL
â”‚   â”‚       â”‚       â””â”€â”€ get_confidence_interval() -> Tuple[float, float]
â”‚   â”‚       â”‚
â”‚   â”‚       â”œâ”€â”€ ðŸ“„ momentum_transfer.py
â”‚   â”‚       â”‚   â””â”€â”€ class MomentumTransfer:
â”‚   â”‚       â”‚       â”œâ”€â”€ transfer_weights(old_weights, new_weights, delta_gamma) -> Tensor:
â”‚   â”‚       â”‚       â”‚   â”œâ”€â”€ decay_rate = 0.15 + 0.05 * abs(delta_gamma)
â”‚   â”‚       â”‚       â”‚   â””â”€â”€ return (1 - decay_rate) * old_weights + decay_rate * new_weights
â”‚   â”‚       â”‚       â””â”€â”€ preserve_momentum(optimizer, decay=0.9):
â”‚   â”‚       â”‚           â””â”€â”€ # Keep optimizer momentum buffers
â”‚   â”‚       â”‚
â”‚   â”‚       â””â”€â”€ ðŸ“„ graduated_response.py
â”‚   â”‚           â””â”€â”€ class GraduatedResponseController:
â”‚   â”‚               â”œâ”€â”€ apply_response(roi_drop: float, current_lambda: float, hard_cap: float):
â”‚   â”‚               â”‚   â”œâ”€â”€ if roi_drop >= -0.01:
â”‚   â”‚               â”‚   â”‚   â””â”€â”€ return current_lambda * 0.85, hard_cap * 0.90
â”‚   â”‚               â”‚   â”œâ”€â”€ if roi_drop >= -0.015:
â”‚   â”‚               â”‚   â”‚   â””â”€â”€ return current_lambda * 0.70, hard_cap * 0.75
â”‚   â”‚               â”‚   â”œâ”€â”€ if roi_drop >= -0.02:
â”‚   â”‚               â”‚   â”‚   â””â”€â”€ return self.rollback_to_previous_regime()
â”‚   â”‚               â”‚   â””â”€â”€ return current_lambda, hard_cap
â”‚   â”‚               â””â”€â”€ rollback_to_previous_regime() -> Tuple[float, float]
â”‚   â”‚
â”‚   â””â”€â”€ ðŸ“ decision/
â”‚       â”œâ”€â”€ ðŸ“„ vsnr.py
â”‚       â”‚   â””â”€â”€ class VSNRCalculator:
â”‚       â”‚       â”œâ”€â”€ calculate(delta_prob: float, variance: float) -> float:
â”‚       â”‚       â”‚   â”œâ”€â”€ vsnr = abs(delta_prob) / sqrt(variance + 1e-6)
â”‚       â”‚       â”‚   â””â”€â”€ return clip(vsnr, 1.5, 3.5)
â”‚       â”‚       â””â”€â”€ RANGE = (1.5, 3.5)
â”‚       â”‚
â”‚       â”œâ”€â”€ ðŸ“„ decay.py
â”‚       â”‚   â””â”€â”€ class TimeDecayCalculator:
â”‚       â”‚       â”œâ”€â”€ calculate(minute: int) -> float:
â”‚       â”‚       â”‚   â””â”€â”€ return 1 / (1 + exp(0.7 * (minute - 85)))
â”‚       â”‚       â””â”€â”€ BREAKPOINT_MINUTE = 85
â”‚       â”‚
â”‚       â”œâ”€â”€ ðŸ“„ cas.py
â”‚       â”‚   â””â”€â”€ class CASCalculator:
â”‚       â”‚       â”œâ”€â”€ calculate(vsnr, decay, confidence_weight, corridor_liquidity) -> float:
â”‚       â”‚       â”‚   â””â”€â”€ return (vsnr * decay * confidence_weight) / corridor_liquidity
â”‚       â”‚       â”œâ”€â”€ get_action(cas: float) -> CASAction:
â”‚       â”‚       â”‚   â”œâ”€â”€ if cas > 1.0: return TRIGGER_MICRO_CYCLE
â”‚       â”‚       â”‚   â”œâ”€â”€ if cas >= 0.8: return PREPARE_POSITION
â”‚       â”‚       â”‚   â””â”€â”€ return MAINTAIN_WEIGHTS
â”‚       â”‚       â””â”€â”€ THRESHOLDS = {"trigger": 1.0, "prepare": 0.8}
â”‚       â”‚
â”‚       â”œâ”€â”€ ðŸ“„ confidence_weight.py
â”‚       â”‚   â””â”€â”€ class ConfidenceWeightCalculator:
â”‚       â”‚       â”œâ”€â”€ calculate(kappa, momentum_corr, vol_idx, depth_ratio) -> float:
â”‚       â”‚       â”‚   â”œâ”€â”€ raw = 0.4 + 0.6 * tanh(kappa * momentum_corr * vol_idx * (1 + depth_ratio))
â”‚       â”‚       â”‚   â””â”€â”€ return clip(raw, 0.4, 1.0)
â”‚       â”‚       â”œâ”€â”€ update_kappa(target_cas, realized_cas, current_kappa) -> float:
â”‚       â”‚       â”‚   â””â”€â”€ return clip(current_kappa + 0.05 * (target - realized), 0.5, 1.5)
â”‚       â”‚       â””â”€â”€ RANGE = (0.4, 1.0)
â”‚       â”‚
â”‚       â”œâ”€â”€ ðŸ“„ gamma.py
â”‚       â”‚   â””â”€â”€ class GammaCalculator:
â”‚       â”‚       â”œâ”€â”€ calculate(market_data) -> float
â”‚       â”‚       â”œâ”€â”€ get_mode(gamma: float) -> MarketMode:
â”‚       â”‚       â”‚   â”œâ”€â”€ if gamma < -0.08: return COORDINATION  # hysteresis: > -0.05
â”‚       â”‚       â”‚   â”œâ”€â”€ if gamma > 0.52: return LEADERSHIP    # hysteresis: < 0.48
â”‚       â”‚       â”‚   â””â”€â”€ return NEUTRAL
â”‚       â”‚       â””â”€â”€ THRESHOLDS = {"coordination": -0.08, "leadership": 0.52}
â”‚       â”‚
â”‚       â””â”€â”€ ðŸ“„ portfolio_correlation.py
â”‚           â””â”€â”€ class PortfolioCorrelationManager:
â”‚               â”œâ”€â”€ calculate_n_eff(weights: np.ndarray, correlation_matrix: np.ndarray) -> float:
â”‚               â”‚   â””â”€â”€ return 1 / (weights.T @ correlation_matrix @ weights)
â”‚               â”œâ”€â”€ adjust_learning_rate(base_eta, n_eff, k) -> float:
â”‚               â”‚   â””â”€â”€ return base_eta * min(1, n_eff / k)
â”‚               â””â”€â”€ compute_lambda_adjustment(mode_mult, avg_corr) -> float
```

---

## DEVAMI â†’ PROJECT_TREE_v3.1_PART4.md (Strategy, Risk, Monitoring)
