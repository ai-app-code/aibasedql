# ğŸ™ï¸ SUPERBET GENESIS v3.1 - BROADCAST LAYER
## SÃ¼per-Rasyonel Dijital Bahis VarlÄ±ÄŸÄ± - YayÄ±n KatmanÄ± Mimari PlanÄ±

**OluÅŸturma:** 04.01.2026  
**Kaynak:** TETRA AI MÃ¼nazara Paneli (4 Tur, 10 LLM, Oy BirliÄŸi)  
**Versiyon:** v3.1 (bettingenesis-v3.1.md ile entegre)  
**Durum:** âœ… ONAYLANDI

---

# ğŸ“Œ BÃ–LÃœM 0: YÃ–NETÄ°CÄ° Ã–ZETÄ°

## AmaÃ§

SUPERBET GENESIS v3.1 sisteminin Ã¼rettiÄŸi tahminleri dÄ±ÅŸ dÃ¼nyaya yayÄ±nlamak iÃ§in **BroadcastPlant** katmanÄ± tasarlandÄ±. Bu katman:

- âœ… Pre-match kuponlarÄ± yayÄ±nlar
- âœ… CanlÄ± pozisyon deÄŸiÅŸikliklerini yayÄ±nlar
- âœ… Platform-agnostic standart format Ã¼retir
- âœ… Mevcut sistemi bozmadan entegre olur

## Hedef Platformlar

| Platform | Ã–ncelik | API |
|----------|---------|-----|
| **X (Twitter)** | P0 | Developer API v2 |
| **Telegram** | P1 | Bot API |
| **Android Push** | P2 | Firebase FCM |

## Kritik Metrikler

| Metrik | Hedef |
|--------|-------|
| YayÄ±n Latency | p99 < 60ms |
| GÃ¼nlÃ¼k Limit | 200 yayÄ±n |
| Filtre EÅŸiÄŸi | Conf>0.65, VSNR>2.2, CAS>1.0 |
| CB Recovery | 15dk Digest Buffer |

---

# ğŸ“Š BÃ–LÃœM 1: MÄ°MARÄ° KONUM

## Sistem AkÄ±ÅŸ DiyagramÄ±

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        SUPERBET GENESIS v3.1                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  API-Football v3 â†’ Kafka â†’ Flink â†’ ClickHouse/Redis                        â”‚
â”‚                                          â†“                                  â”‚
â”‚                                   Feast Feature Store                       â”‚
â”‚                                          â†“                                  â”‚
â”‚                                   KServe Inference                          â”‚
â”‚                                          â†“                                  â”‚
â”‚                                   HRL Agents                                â”‚
â”‚                                   (Pre-match DQN / Live LSTM+PPO)           â”‚
â”‚                                          â†“                                  â”‚
â”‚                                   Risk Management                           â”‚
â”‚                                          â†“                                  â”‚
â”‚                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚                              â”‚   ğŸ™ï¸ BROADCAST LAYER  â”‚ â† YENÄ° EKLENEN      â”‚
â”‚                              â”‚      (BroadcastPlant) â”‚                      â”‚
â”‚                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚                                          â†“                                  â”‚
â”‚                                   Observability                             â”‚
â”‚                                   (Prometheus/Grafana)                      â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Konum GerekÃ§esi

| Karar | GerekÃ§e | Oy |
|-------|---------|-----|
| Risk Management **SONRASI** | Sadece onaylanmÄ±ÅŸ tahminler yayÄ±nlanÄ±r | 8/8 âœ… |
| Async Sidecar Pattern | Ana akÄ±ÅŸ etkilenmez | 8/8 âœ… |
| Observability Ã–NCESÄ° | YayÄ±n metrikleri Prometheus'a gider | 8/8 âœ… |

---

# ğŸ”„ BÃ–LÃœM 2: BROADCAST LAYER MÄ°MARÄ°SÄ°

## DetaylÄ± AkÄ±ÅŸ

```
Risk Management
       â†“
       â”‚ Kafka: risk.verified
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      BROADCAST PLANT                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                      â”‚
â”‚  â”‚  CloudEvents        â”‚  â€¢ Filtre: Conf>0.65, VSNR>2.2       â”‚
â”‚  â”‚  Formatter          â”‚  â€¢ Transform: Raw + Formatted        â”‚
â”‚  â”‚                     â”‚  â€¢ Priority Score hesapla            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                      â”‚
â”‚             â†“                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                      â”‚
â”‚  â”‚  Priority           â”‚  â€¢ max_poll_records=5                â”‚
â”‚  â”‚  Dispatcher         â”‚  â€¢ manual commit                     â”‚
â”‚  â”‚                     â”‚  â€¢ priority header sorting           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                      â”‚
â”‚             â†“                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚  Kafka Per-Platform Outbox Topics:          â”‚              â”‚
â”‚  â”‚  â€¢ broadcast.outbox.twitter                 â”‚              â”‚
â”‚  â”‚  â€¢ broadcast.outbox.telegram                â”‚              â”‚
â”‚  â”‚  â€¢ broadcast.outbox.android                 â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚             â†“                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚  Platform Adapters (Consumer Groups):       â”‚              â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚              â”‚
â”‚  â”‚  â”‚ TwitterAdapter                      â”‚    â”‚              â”‚
â”‚  â”‚  â”‚ + Circuit Breaker (Resilience4j)    â”‚    â”‚              â”‚
â”‚  â”‚  â”‚ + Full Jitter Retry                 â”‚    â”‚              â”‚
â”‚  â”‚  â”‚ + Token Bucket Rate Limiter         â”‚    â”‚              â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚              â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚              â”‚
â”‚  â”‚  â”‚ TelegramAdapter                     â”‚    â”‚              â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚              â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚              â”‚
â”‚  â”‚  â”‚ AndroidPushAdapter                  â”‚    â”‚              â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚             â†“                                                 â”‚
â”‚        â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”                                            â”‚
â”‚        â†“         â†“                                            â”‚
â”‚   External   Digest Buffer                                    â”‚
â”‚   Platforms  (CB OPEN durumunda)                              â”‚
â”‚                  â†“                                            â”‚
â”‚              15dk Timeout                                     â”‚
â”‚                  â†“                                            â”‚
â”‚              Batch Retry                                      â”‚
â”‚                  â†“                                            â”‚
â”‚              DLQ (Final)                                      â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
 Prometheus Metrics
```

---

# ğŸ“‹ BÃ–LÃœM 3: EVENT FORMATI

## CloudEvents v1.0 StandardÄ±

> **Karar:** CloudEvents v1.0 standardÄ± kabul edildi (7/8 oy)  
> **GerekÃ§e:** Mevcut Kafka pipeline'da `football.match.update` zaten CloudEvents kullanÄ±yor. Interoperability saÄŸlar.

### Tam Payload ÅemasÄ±

```json
{
  "specversion": "1.0",
  "type": "com.superbet.prediction.published",
  "source": "/plant/broadcast",
  "id": "pred-${match_id}-${timestamp}",
  "datacontenttype": "application/json",
  "time": "2026-01-04T15:30:00Z",
  "data": {
    "match_id": "ENG1_20260104_ARS_LIV",
    "kickoff": "2026-01-04T17:30:00Z",
    "teams": {
      "home": "Arsenal",
      "away": "Liverpool"
    },
    "prediction": {
      "pick": "H",
      "home_win": 0.42,
      "draw": 0.28,
      "away_win": 0.30
    },
    "odds": {
      "home_win": 2.10,
      "draw": 3.40,
      "away_win": 3.50
    },
    "metrics": {
      "confidence": 0.72,
      "vsnr": 2.45,
      "cas": 1.15,
      "kelly_fraction": 0.08,
      "gamma": 0.58,
      "risk_score": 0.03
    },
    "formatted": {
      "twitter": "âš½ï¸ Arsenal vs Liverpool: Ev 42% @2.10 | Conf:72% VSNR:2.45 #SuperbetGenesis",
      "telegram": "ğŸ¯ *Arsenal* vs *Liverpool*\n\nğŸ  Ev Sahibi: 42% @2.10\nğŸ“Š GÃ¼ven: 72%\nğŸ“ˆ VSNR: 2.45\nğŸ² CAS: 1.15\n\n#SuperbetGenesis",
      "android": {
        "title": "Arsenal vs Liverpool",
        "body": "Ev Sahibi KazanÄ±r 42% | GÃ¼ven: 72%"
      }
    },
    "metadata": {
      "agent_type": "prematch",
      "model_version": "v3.1",
      "priority_score": 0.0864
    }
  }
}
```

### Raw vs Formatted AyrÄ±mÄ±

| Alan | KullanÄ±m | TÃ¼ketici |
|------|----------|----------|
| `data.prediction` | Raw probability | Developer API, Analytics |
| `data.metrics` | Raw metrikler | Monitoring, Debugging |
| `data.formatted.twitter` | 280 karakter tweet | TwitterAdapter |
| `data.formatted.telegram` | Markdown mesaj | TelegramAdapter |
| `data.formatted.android` | Push notification | AndroidAdapter |

---

# ğŸ¯ BÃ–LÃœM 4: FÄ°LTRELEME VE Ã–NCELÄ°KLENDÄ°RME

## Filtre EÅŸikleri

> **Karar:** BirleÅŸik filtre eÅŸiÄŸi kabul edildi (7/8 oy)

| Metrik | EÅŸik | GerekÃ§e |
|--------|------|---------|
| **Confidence** | > 0.65 | Referans 0.6'dan +0.05 gÃ¼rÃ¼ltÃ¼ azaltma |
| **VSNR** | > 2.2 | Sinyal gÃ¼cÃ¼ garantisi |
| **CAS** | > 1.0 | Adaptasyon skoru minimum |

### Filtre Implementasyonu

```python
class BroadcastFilter:
    """
    TETRA Panel KararÄ±: Conf>0.65 + VSNR>2.2 + CAS>1.0
    """
    THRESHOLDS = {
        "confidence": 0.65,
        "vsnr": 2.2,
        "cas": 1.0
    }
    
    def should_broadcast(self, prediction: dict) -> tuple[bool, float]:
        metrics = prediction["metrics"]
        
        # Filtre kontrolÃ¼
        if metrics["confidence"] < self.THRESHOLDS["confidence"]:
            return False, 0.0
        if metrics["vsnr"] < self.THRESHOLDS["vsnr"]:
            return False, 0.0
        if metrics["cas"] < self.THRESHOLDS["cas"]:
            return False, 0.0
        
        # Priority score hesapla
        priority = self.calculate_priority(metrics)
        return True, priority
```

## Priority Score FormÃ¼lÃ¼

> **Karar:** Logaritmik + Clipping yaklaÅŸÄ±mÄ± kabul edildi  
> **KatkÄ±lar:** [Alfa] log1p Ã¶nerisi + [Gamma] clipping stratejisi

### Nihai FormÃ¼l

```python
import numpy as np

class PriorityScorer:
    """
    Priority Score Formula (TETRA Panel OnaylÄ±):
    
    S = (Conf Ã— Kelly) Ã— clip(log1p(VSNR), 1.0, 1.5) Ã— clip(sqrt(CAS), 1.0, 1.2)
    
    GerekÃ§eler:
    - log1p(VSNR): Outlier'larÄ±n kuyruÄŸu bloke etmesini engeller
    - sqrt(CAS): DoÄŸrusal olmayan, eÅŸik sonrasÄ± sÄ±nÄ±rlÄ± artÄ±ÅŸ
    - Clipping: UÃ§ deÄŸerlerin sistem dengesini bozmasÄ±nÄ± Ã¶nler
    """
    
    def calculate(self, prediction: dict) -> float:
        metrics = prediction["metrics"]
        
        conf = metrics["confidence"]
        kelly = metrics["kelly_fraction"]
        vsnr = metrics["vsnr"]
        cas = metrics["cas"]
        
        # Base score
        base_score = conf * kelly
        
        # VSNR multiplier (logarithmic + clipped)
        vsnr_mult = min(max(np.log1p(vsnr), 1.0), 1.5)
        
        # CAS multiplier (sqrt + clipped)
        cas_mult = min(max(np.sqrt(cas), 1.0), 1.2)
        
        # Final priority score
        priority_score = base_score * vsnr_mult * cas_mult
        
        return priority_score
```

### Priority Ã–rnekleri

| Conf | Kelly | VSNR | CAS | Priority Score |
|------|-------|------|-----|----------------|
| 0.72 | 0.08 | 2.45 | 1.15 | ~0.086 |
| 0.85 | 0.12 | 3.10 | 1.35 | ~0.141 |
| 0.68 | 0.05 | 2.25 | 1.02 | ~0.042 |

---

# ğŸ”§ BÃ–LÃœM 5: ADAPTER PATTERN

## BaseAdapter Interface

```python
from abc import ABC, abstractmethod
from dataclasses import dataclass
from typing import Optional

@dataclass
class Result:
    success: bool = False
    retry: bool = False
    reason: Optional[str] = None
    error: Optional[Exception] = None

class BaseAdapter(ABC):
    """
    TÃ¼m platform adapter'larÄ± bu interface'i implemente eder.
    SPI (Service Provider Interface) pattern ile dinamik yÃ¼kleme.
    """
    
    @abstractmethod
    async def publish(self, cloud_event: dict) -> Result:
        """Publish CloudEvent to target platform"""
        pass
    
    @abstractmethod
    def get_platform_name(self) -> str:
        """Return platform identifier"""
        pass
```

## TwitterAdapter Implementasyonu

```python
import asyncio
import random
from resilience4j import CircuitBreaker

class TwitterAdapter(BaseAdapter):
    """
    X (Twitter) Platform Adapter
    
    Features:
    - Token Bucket Rate Limiting
    - Circuit Breaker (Resilience4j)
    - Full Jitter Exponential Backoff
    """
    
    def __init__(
        self, 
        client: TwitterClient, 
        rate_limiter: PlatformRateLimiter,
        circuit_breaker: CircuitBreaker
    ):
        self.client = client
        self.rate_limiter = rate_limiter
        self.cb = circuit_breaker
        self.backoff = FullJitterBackoff(base=1.0, cap=60.0, max_attempts=5)
    
    def get_platform_name(self) -> str:
        return "twitter"
    
    async def publish(self, event: dict) -> Result:
        # Circuit Breaker check
        if self.cb.state == "OPEN":
            return Result(retry=False, reason="cb_open")
        
        # Rate limiter check
        if not await self.rate_limiter.try_acquire("twitter", 1):
            return Result(retry=True, reason="rate_limited")
        
        try:
            text = event["data"]["formatted"]["twitter"]
            await self.client.tweet(text)
            self.cb.record_success()
            return Result(success=True)
        except Exception as e:
            self.cb.record_failure()
            return Result(success=False, error=e)
    
    async def publish_with_retry(self, event: dict) -> Result:
        """Full Jitter Exponential Backoff ile retry"""
        for attempt in range(self.backoff.max_attempts):
            result = await self.publish(event)
            
            if result.success:
                return result
            
            if not result.retry:
                # CB open veya permanent failure
                return result
            
            # Exponential backoff with full jitter
            wait_time = await self.backoff.calculate_wait(attempt)
            await asyncio.sleep(wait_time)
        
        return Result(retry=False, reason="max_attempts_exceeded")
```

## TelegramAdapter Implementasyonu

```python
class TelegramAdapter(BaseAdapter):
    """Telegram Bot API Adapter"""
    
    def __init__(self, bot: TelegramBot, chat_id: str, rate_limiter: PlatformRateLimiter):
        self.bot = bot
        self.chat_id = chat_id
        self.rate_limiter = rate_limiter
    
    def get_platform_name(self) -> str:
        return "telegram"
    
    async def publish(self, event: dict) -> Result:
        if not await self.rate_limiter.try_acquire("telegram", 1):
            return Result(retry=True, reason="rate_limited")
        
        try:
            text = event["data"]["formatted"]["telegram"]
            await self.bot.send_message(
                chat_id=self.chat_id,
                text=text,
                parse_mode="Markdown"
            )
            return Result(success=True)
        except Exception as e:
            return Result(success=False, error=e)
```

## SPI Registration

```
META-INF/services/
â””â”€â”€ com.superbet.broadcast.adapters
    â”œâ”€â”€ com.superbet.broadcast.adapters.TwitterAdapter
    â”œâ”€â”€ com.superbet.broadcast.adapters.TelegramAdapter
    â””â”€â”€ com.superbet.broadcast.adapters.AndroidPushAdapter
```

---

# â±ï¸ BÃ–LÃœM 6: RATE LIMITING

## Token Bucket Stratejisi

> **Karar:** Redis Token Bucket (per-platform) kabul edildi (8/8 oy)

### Platform Limitleri

| Platform | GÃ¼nlÃ¼k | Saatlik | Window |
|----------|--------|---------|--------|
| Twitter | 50 | 10 | 1h |
| Telegram | 200 | 30 | 1h |
| Android | 1000 | 100 | 1h |
| **Global** | **200** | - | 24h |

### Implementasyon

```python
import time
import redis

class PlatformRateLimiter:
    """
    Redis Token Bucket Rate Limiter
    Key format: broadcast:limits:{platform}
    """
    
    LIMITS = {
        "twitter": {"daily": 50, "hourly": 10, "refill_rate": 10/3600},
        "telegram": {"daily": 200, "hourly": 30, "refill_rate": 30/3600},
        "android": {"daily": 1000, "hourly": 100, "refill_rate": 100/3600},
        "global": {"daily": 200, "hourly": None, "refill_rate": 200/86400}
    }
    
    def __init__(self, redis_client: redis.Redis):
        self.redis = redis_client
    
    async def try_acquire(self, platform: str, tokens: int = 1) -> bool:
        key = f"broadcast:limits:{platform}"
        limits = self.LIMITS[platform]
        
        # Lua script for atomic token bucket operation
        script = """
        local key = KEYS[1]
        local tokens_requested = tonumber(ARGV[1])
        local max_tokens = tonumber(ARGV[2])
        local refill_rate = tonumber(ARGV[3])
        local now = tonumber(ARGV[4])
        
        local bucket = redis.call('HMGET', key, 'tokens', 'last_refill')
        local current_tokens = tonumber(bucket[1]) or max_tokens
        local last_refill = tonumber(bucket[2]) or now
        
        -- Refill tokens
        local elapsed = now - last_refill
        current_tokens = math.min(max_tokens, current_tokens + elapsed * refill_rate)
        
        if current_tokens >= tokens_requested then
            current_tokens = current_tokens - tokens_requested
            redis.call('HMSET', key, 'tokens', current_tokens, 'last_refill', now)
            return 1
        else
            redis.call('HMSET', key, 'tokens', current_tokens, 'last_refill', now)
            return 0
        end
        """
        
        result = await self.redis.eval(
            script,
            1,
            key,
            tokens,
            limits["hourly"],
            limits["refill_rate"],
            time.time()
        )
        
        return result == 1
```

---

# ğŸ›¡ï¸ BÃ–LÃœM 7: RESILIENCE MEKANÄ°ZMALARI

## Circuit Breaker

> **Karar:** Resilience4j per adapter kabul edildi (8/8 oy)

### KonfigÃ¼rasyon

| Parametre | DeÄŸer | AÃ§Ä±klama |
|-----------|-------|----------|
| Failure Threshold | 50% | Hata oranÄ± eÅŸiÄŸi |
| Timeout | 5 dakika | CB OPEN sÃ¼resi |
| Half-Open Calls | 3 | Test Ã§aÄŸrÄ±sÄ± sayÄ±sÄ± |

### Implementasyon

```python
import asyncio
from enum import Enum
from dataclasses import dataclass
from typing import Callable

class CBState(Enum):
    CLOSED = "CLOSED"
    OPEN = "OPEN"
    HALF_OPEN = "HALF_OPEN"

@dataclass
class CircuitBreakerConfig:
    failure_threshold: float = 0.5
    timeout_seconds: int = 300  # 5 dakika
    half_open_calls: int = 3

class CircuitBreaker:
    """
    TETRA Panel KararÄ±: Per-adapter Circuit Breaker
    %50 hata oranÄ±nda OPEN â†’ 5dk bekle â†’ HALF_OPEN â†’ test
    """
    
    def __init__(self, config: CircuitBreakerConfig, digest_buffer: "DigestBuffer"):
        self.config = config
        self.digest_buffer = digest_buffer
        self.state = CBState.CLOSED
        self.failure_count = 0
        self.success_count = 0
        self.total_count = 0
        self._half_open_count = 0
    
    @property
    def failure_rate(self) -> float:
        if self.total_count == 0:
            return 0.0
        return self.failure_count / self.total_count
    
    async def call(self, adapter: BaseAdapter, event: dict) -> Result:
        if self.state == CBState.OPEN:
            # Digest Buffer'a yÃ¶nlendir
            await self.digest_buffer.buffer_event(event, adapter.get_platform_name())
            return Result(retry=False, reason="cb_open")
        
        if self.state == CBState.HALF_OPEN:
            if self._half_open_count >= self.config.half_open_calls:
                return Result(retry=False, reason="half_open_limit")
            self._half_open_count += 1
        
        try:
            result = await adapter.publish(event)
            self._record_result(result.success)
            return result
        except Exception as e:
            self._record_result(False)
            raise
    
    def _record_result(self, success: bool):
        self.total_count += 1
        if success:
            self.success_count += 1
            if self.state == CBState.HALF_OPEN:
                self._reset()
        else:
            self.failure_count += 1
            self._check_threshold()
    
    def _check_threshold(self):
        if self.failure_rate > self.config.failure_threshold:
            self.state = CBState.OPEN
            asyncio.create_task(self._schedule_half_open())
    
    async def _schedule_half_open(self):
        await asyncio.sleep(self.config.timeout_seconds)
        self.state = CBState.HALF_OPEN
        self._half_open_count = 0
    
    def _reset(self):
        self.state = CBState.CLOSED
        self.failure_count = 0
        self.success_count = 0
        self.total_count = 0
```

## Digest Buffer

> **Karar:** DLQ yerine Digest Buffer tercih edildi (7/8 oy)  
> **GerekÃ§e:** KullanÄ±cÄ±ya bayat spam (DLQ replay) yerine Ã¶zet gÃ¶nderimi daha saÄŸlÄ±klÄ±

### Mekanizma

```
CB OPEN â†’ Event Digest Buffer'a dÃ¼ÅŸer
         â†“
     15dk bekle (Redis SETEX TTL=900)
         â†“
     CB CLOSED â†’ Batch retry
         â†“
     BaÅŸarÄ±sÄ±z â†’ DLQ (final)
```

### Implementasyon

```python
import json
import time

class DigestBuffer:
    """
    TETRA Panel KararÄ±: 15dk Digest Buffer
    
    Key format: broadcast:digest:{platform}:{bucket_id}
    bucket_id = int(timestamp // 900)  # 15 dakikalÄ±k bucket'lar
    """
    
    TTL_SECONDS = 900  # 15 dakika
    
    def __init__(self, redis_client: redis.Redis):
        self.redis = redis_client
    
    def _get_bucket_key(self, platform: str) -> str:
        bucket_id = int(time.time() // self.TTL_SECONDS)
        return f"broadcast:digest:{platform}:{bucket_id}"
    
    async def buffer_event(self, event: dict, platform: str):
        """CB OPEN durumunda event'i buffer'a ekle"""
        key = self._get_bucket_key(platform)
        event_json = json.dumps(event)
        
        # RPUSH + EXPIRE (atomic deÄŸil ama yeterli)
        await self.redis.rpush(key, event_json)
        await self.redis.expire(key, self.TTL_SECONDS * 2)  # 30dk TTL
    
    async def flush_bucket(self, platform: str, bucket_key: str, adapter: BaseAdapter) -> dict:
        """Bucket'taki tÃ¼m event'leri batch olarak gÃ¶nder"""
        events = await self.redis.lrange(bucket_key, 0, -1)
        
        results = {"success": 0, "failed": 0}
        
        for event_json in events:
            event = json.loads(event_json)
            result = await adapter.publish_with_retry(event)
            
            if result.success:
                results["success"] += 1
            else:
                results["failed"] += 1
                # DLQ'ya gÃ¶nder
                await self._send_to_dlq(event, platform, result.reason)
        
        # BaÅŸarÄ±lÄ± flush sonrasÄ± bucket'Ä± sil
        await self.redis.delete(bucket_key)
        
        return results
    
    async def _send_to_dlq(self, event: dict, platform: str, reason: str):
        """Final failure â†’ DLQ"""
        dlq_event = {
            "original_event": event,
            "platform": platform,
            "failure_reason": reason,
            "timestamp": time.time()
        }
        await self.kafka_producer.send("broadcast.dlq", dlq_event)
```

## Full Jitter Exponential Backoff

> **Karar:** Full Jitter stratejisi kabul edildi  
> **GerekÃ§e:** Thundering herd problemini Ã¶nler

### FormÃ¼l

```
wait = min(cap, base Ã— 2^attempt) / 2 + random(0, wait/2)
```

### Implementasyon

```python
import random
import asyncio

class FullJitterBackoff:
    """
    TETRA Panel KararÄ±: Full Jitter Exponential Backoff
    
    Formula: wait = min(cap, base * 2**attempt) / 2 + random(0, wait/2)
    
    Parameters:
    - base: 1 saniye
    - cap: 60 saniye
    - max_attempts: 5
    """
    
    def __init__(self, base: float = 1.0, cap: float = 60.0, max_attempts: int = 5):
        self.base = base
        self.cap = cap
        self.max_attempts = max_attempts
    
    async def calculate_wait(self, attempt: int) -> float:
        """
        Full Jitter: Thundering herd'Ã¼ Ã¶nler
        
        Attempt 0: 0.5-1.0s
        Attempt 1: 1.0-2.0s
        Attempt 2: 2.0-4.0s
        Attempt 3: 4.0-8.0s
        Attempt 4: 8.0-16.0s (capped at 60s)
        """
        inner = min(self.cap, self.base * (2 ** attempt))
        wait = inner / 2 + random.uniform(0, inner / 2)
        return wait
```

---

# ğŸ“¡ BÃ–LÃœM 8: KAFKA TOPOLOGY

## Topic YapÄ±sÄ±

> **Karar:** Per-platform outbox topics kabul edildi (7/8 oy)  
> **GerekÃ§e:** Bulkhead Pattern - X API yavaÅŸlarsa Telegram etkilenmez

```
Kafka Topics:
â”‚
â”œâ”€â”€ risk.verified                   â† Input (Risk Management'dan)
â”‚   â””â”€â”€ Producer: RiskManagementPlant
â”‚   â””â”€â”€ Consumer: broadcast-plant-formatter
â”‚
â”œâ”€â”€ broadcast.queue.priority        â† Internal (Priority Dispatcher)
â”‚   â””â”€â”€ Headers: priority_score, platform
â”‚   â””â”€â”€ Consumer: broadcast-plant-dispatcher
â”‚
â”œâ”€â”€ broadcast.outbox.twitter        â† Output (Platform-specific)
â”‚   â””â”€â”€ Consumer Group: twitter-adapter-consumer
â”‚
â”œâ”€â”€ broadcast.outbox.telegram       â† Output
â”‚   â””â”€â”€ Consumer Group: telegram-adapter-consumer
â”‚
â”œâ”€â”€ broadcast.outbox.android        â† Output
â”‚   â””â”€â”€ Consumer Group: android-adapter-consumer
â”‚
â”œâ”€â”€ broadcast.digest.buffer         â† CB Fallback (Internal)
â”‚   â””â”€â”€ Consumer: digest-flusher (cron: every 15min)
â”‚
â””â”€â”€ broadcast.dlq                   â† Dead Letter Queue (Final)
    â””â”€â”€ Consumer: dlq-processor (manual review)
```

## Consumer KonfigÃ¼rasyonu

```python
KAFKA_CONSUMER_CONFIG = {
    "bootstrap.servers": "kafka:9092",
    "group.id": "broadcast-plant-priority",
    "auto.offset.reset": "earliest",
    "enable.auto.commit": False,     # TETRA KararÄ±: Manual commit
    "max.poll.records": 5,           # TETRA KararÄ±: Starvation Ã¶nleme
    "fetch.min.bytes": 1024,
    "fetch.max.wait.ms": 500,
    "receive.buffer.bytes": 65536
}
```

## Priority Consumer

```python
class PriorityConsumer:
    """
    Priority header'a gÃ¶re sÄ±ralama + batch processing
    max_poll_records=5 ile starvation Ã¶nlenir
    """
    
    async def consume(self):
        messages = await self.consumer.poll(timeout_ms=1000)
        
        # Priority'ye gÃ¶re sÄ±rala
        prioritized = []
        for topic_partition, records in messages.items():
            for record in records:
                priority = float(record.headers.get("priority", 0.0))
                prioritized.append((priority, record))
        
        # YÃ¼ksek priority Ã¶nce
        prioritized.sort(key=lambda x: -x[0])
        
        # Batch process
        batch = prioritized[:5]
        
        results = await asyncio.gather(*[
            self.process_message(record) 
            for _, record in batch
        ])
        
        # Manual commit
        await self.consumer.commit()
```

---

# ğŸ“Š BÃ–LÃœM 9: MONITORING VE ALERTING

## Prometheus Metrics

```yaml
# Counter metrics
broadcast_published_total{platform="twitter", priority="high"}
broadcast_published_total{platform="telegram", priority="low"}
broadcast_dropped_total{reason="filter_low_confidence"}
broadcast_dropped_total{reason="filter_low_vsnr"}
broadcast_dropped_total{reason="filter_low_cas"}
broadcast_dropped_total{reason="rate_limited"}

# Gauge metrics
broadcast_circuit_breaker_state{platform="twitter"}  # 0=CLOSED, 1=OPEN, 2=HALF_OPEN
broadcast_rate_limit_tokens{platform="twitter"}
broadcast_digest_buffer_size{platform="twitter"}
broadcast_digest_staleness_seconds{platform="twitter"}

# Histogram metrics
broadcast_latency_seconds{platform="twitter", quantile="0.5"}
broadcast_latency_seconds{platform="twitter", quantile="0.99"}

# Error metrics
broadcast_error_rate{platform="twitter"}
broadcast_retry_count{platform="twitter"}
```

## Alert Rules

```yaml
groups:
  - name: broadcast_alerts
    rules:
      # Digest Buffer Staleness Alert
      - alert: DigestBufferStale
        expr: broadcast_digest_staleness_seconds > 900
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Digest Buffer {{ $labels.platform }} stale"
          description: "Digest Buffer for {{ $labels.platform }} has messages older than 15 minutes"
      
      # Circuit Breaker Open Alert
      - alert: CircuitBreakerOpen
        expr: broadcast_circuit_breaker_state == 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Circuit Breaker OPEN for {{ $labels.platform }}"
      
      # High Error Rate Alert
      - alert: BroadcastHighErrorRate
        expr: broadcast_error_rate > 0.1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High broadcast error rate for {{ $labels.platform }}"
      
      # Rate Limit Approaching
      - alert: RateLimitApproaching
        expr: broadcast_rate_limit_tokens < 5
        for: 1m
        labels:
          severity: info
        annotations:
          summary: "Rate limit tokens low for {{ $labels.platform }}"
```

## Grafana Dashboard Panelleri

| Panel | Metrik | GÃ¶rselleÅŸtirme |
|-------|--------|----------------|
| YayÄ±n/Saat | `rate(broadcast_published_total[1h])` | Time series |
| Platform DaÄŸÄ±lÄ±mÄ± | `broadcast_published_total by platform` | Pie chart |
| CB Durumu | `broadcast_circuit_breaker_state` | Stat |
| Drop Nedenleri | `broadcast_dropped_total by reason` | Bar chart |
| Latency P99 | `broadcast_latency_seconds{quantile="0.99"}` | Gauge |
| Digest Buffer | `broadcast_digest_buffer_size` | Time series |

---

# ğŸ”— BÃ–LÃœM 10: bettingenesis-v3.1 ENTEGRASYONU

## Mevcut Sistem BileÅŸenleri ile Ä°liÅŸki

| v3.1 BileÅŸeni | Broadcast Entegrasyonu | Notlar |
|---------------|------------------------|--------|
| **HRL Agents** | Tahmin Ã¼retir â†’ `risk.verified` topic | Pre-match DQN + Live LSTM+PPO |
| **Risk Management** | Onay sonrasÄ± broadcast'e gÃ¶nderir | VaR, CVaR, Kelly kontrolleri |
| **VSNR** | Filtre eÅŸiÄŸi: > 2.2 | Priority score Ã§arpanÄ± |
| **CAS** | Filtre eÅŸiÄŸi: > 1.0 | Priority score Ã§arpanÄ± |
| **Confidence** | Filtre eÅŸiÄŸi: > 0.65 | Ana filtre kriteri |
| **Kelly Fraction** | Priority score | `Conf Ã— Kelly` base score |
| **Gamma (Î³)** | CloudEvents data'da expose | Liderlik/EÅŸgÃ¼dÃ¼m modu bilgisi |
| **Circuit Breaker** | Per-adapter Resilience4j | Mevcut CB pattern ile uyumlu |
| **Prometheus** | Broadcast metrikleri eklendi | Mevcut monitoring altyapÄ±sÄ± |

## Yeni Kafka Topics

Mevcut topic'lere ek olarak:

```
# Mevcut (v3.1)
prematch, live, odds, graph_events, sentiment

# Yeni (Broadcast Layer)
risk.verified            â† Risk Management Ã§Ä±kÄ±ÅŸÄ±
broadcast.queue.priority â† Internal priority queue
broadcast.outbox.twitter â† Twitter adapter
broadcast.outbox.telegramâ† Telegram adapter
broadcast.outbox.android â† Android adapter
broadcast.digest.buffer  â† CB fallback
broadcast.dlq            â† Dead letter queue
```

## Handover Protocol Entegrasyonu

```python
# Pre-match tahminleri yayÄ±nlanÄ±r
class PreMatchAgent:
    def produce_prediction(self):
        prediction = self.dqn.predict(state)
        # Risk Management'a gÃ¶nder
        await kafka.send("risk.verified", prediction)
        # â†’ BroadcastPlant â†’ Twitter'da "âš½ï¸ Arsenal vs Liverpool..." tweet'i

# Live tahminleri de yayÄ±nlanÄ±r
class LiveAgent:
    def on_live_event(self, event):
        updated_prediction = self.lstm_ppo.update(event)
        if self.should_update_position(updated_prediction):
            await kafka.send("risk.verified", updated_prediction)
            # â†’ BroadcastPlant â†’ Twitter'da "ğŸ”„ Pozisyon gÃ¼ncellendi..." tweet'i
```

---

# ğŸ“‹ BÃ–LÃœM 11: MÃœNAZARA Ã–ZETÄ°

## KatÄ±lÄ±mcÄ±lar ve KatkÄ±larÄ±

| KatÄ±lÄ±mcÄ± | Rol | Ana KatkÄ± |
|-----------|-----|-----------|
| **Nexus** | BaÅŸ Mimar/ModeratÃ¶r | MÃ¼nazara yÃ¶netimi, oylama koordinasyonu |
| **DevOps** | xAI | Tek topic savunusu (azÄ±nlÄ±k), Kafka config |
| **Alfa** | Google | log1p VSNR Ã¶nerisi, CloudEvents desteÄŸi |
| **Beta** | Google | Bulkhead Pattern, Full Jitter Ã¶nerisi |
| **Gamma** | OpenAI | Clipping stratejisi, Priority Score birleÅŸtirme |
| **Delta** | MoonshotAI | ArgoCD entegrasyonu, Staleness alert |
| **Epsilon** | Qwen | SLO uyumu, mevcut metrik kullanÄ±mÄ± |
| **Zeta** | Z.AI | Digest Buffer UX faydalarÄ± |
| **Theta** | OpenAI | Oylama sonuÃ§larÄ± aÃ§Ä±klamasÄ± |
| **Kappa** | MiniMax | Final Blueprint hazÄ±rlÄ±ÄŸÄ± |

## Oylama SonuÃ§larÄ±

| Karar | Oy | SonuÃ§ |
|-------|-----|-------|
| Mimari Konum: Risk Mgmt SONRASI | 8/8 | âœ… Kabul |
| Adapter Pattern: BaseAdapter | 8/8 | âœ… Kabul |
| Rate Limiting: Redis Token Bucket | 8/8 | âœ… Kabul |
| Topic: Per-platform outbox | 7/8 | âœ… Kabul |
| Format: CloudEvents v1.0 | 7/8 | âœ… Kabul |
| Filtre: Conf>0.65+VSNR>2.2+CAS>1.0 | 7/8 | âœ… Kabul |
| CB Fallback: Digest Buffer | 7/8 | âœ… Kabul |
| Priority Score: log1p+sqrt+clip | KonsensÃ¼s | âœ… Kabul |
| Retry: Full Jitter | KonsensÃ¼s | âœ… Kabul |

## Ã‡Ã¶zÃ¼len Ã‡atÄ±ÅŸmalar

| Ã‡atÄ±ÅŸma | Pozisyon A | Pozisyon B | Kazanan |
|---------|------------|------------|---------|
| Topic mimarisi | Tek topic (DevOps) | Per-platform (Ã‡oÄŸunluk) | Per-platform |
| CB Fallback | DLQ (DevOps) | Digest Buffer (Ã‡oÄŸunluk) | Digest Buffer |
| Priority Score | Lineer (Beta) | Logaritmik (Alfa) | Logaritmik+Clipping |

---

# ğŸ¯ BÃ–LÃœM 12: SONUÃ‡ VE SONRAKI ADIMLAR

## Tamamlanan Kararlar

- âœ… Broadcast Layer mimarisi tanÄ±mlandÄ±
- âœ… CloudEvents v1.0 formatÄ± belirlendi
- âœ… Filtre eÅŸikleri kesinleÅŸti
- âœ… Priority Score formÃ¼lÃ¼ onaylandÄ±
- âœ… Kafka topology tasarlandÄ±
- âœ… Resilience mekanizmalarÄ± belirlendi
- âœ… Monitoring metrikleri tanÄ±mlandÄ±

## Sonraki AdÄ±mlar

| AdÄ±m | Ã–ncelik | Tahmini SÃ¼re |
|------|---------|--------------|
| X Developer hesabÄ± aÃ§ma | P0 | 1 gÃ¼n |
| TwitterAdapter POC | P0 | 3 gÃ¼n |
| BroadcastPlant service skeleton | P0 | 2 gÃ¼n |
| Kafka topic'leri oluÅŸturma | P1 | 1 gÃ¼n |
| Redis rate limiter kurulumu | P1 | 1 gÃ¼n |
| Circuit Breaker implementasyonu | P1 | 2 gÃ¼n |
| Prometheus metrikleri ekleme | P2 | 1 gÃ¼n |
| Grafana dashboard | P2 | 1 gÃ¼n |
| TelegramAdapter | P3 | 2 gÃ¼n |
| AndroidPushAdapter | P3 | 2 gÃ¼n |

## Ä°lk MVP Scope

**Hedef:** X (Twitter) platformuna tek tip tahmin yayÄ±nÄ±

1. BroadcastPlant service
2. TwitterAdapter
3. Temel filtreleme
4. Rate limiting
5. Prometheus metrikleri

---

# ğŸ“š REFERANSLAR

| Dosya | Ä°liÅŸki |
|-------|--------|
| `bettingenesis-v3.1.md` | Ana sistem mimarisi |
| `PROJECT_TREE_v3.1.md` | Proje yapÄ±sÄ± |
| `FRONTEND_ARCHITECTURE_v1.0.md` | Frontend blueprint |
| `BROADCAST_MUNAZARA_PROMPT.md` | MÃ¼nazara promptu |

---

**Broadcast Layer Blueprint v1.0 - ONAYLANDI âœ…**

*TETRA AI MÃ¼nazara Paneli - 04.01.2026*
